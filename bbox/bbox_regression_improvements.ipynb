{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb0eed4",
   "metadata": {},
   "source": [
    "In object detection, we perform both bounding box regression and classification. While classification losses are standardized with `Focal Loss`. In bbox regressor, we have seen various improvements from `L1 Loss` and `L2 Loss` over a period of time. We will see what those loss functions are here.\n",
    "- IoU\n",
    "- Generalized IoU (GIoU)\n",
    "- Distance IoU (DIoU)\n",
    "- Complete IoU (CIoU)\n",
    "\n",
    "Emperically, CIoU is the SOTA now but lets see everything to understand how we reached here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f0409",
   "metadata": {},
   "source": [
    "> Lets take two examples to understand different loss functions\n",
    "- gt and pred boxes overlapped \n",
    "- gt and pred boxes with no overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cb1dc",
   "metadata": {},
   "source": [
    "> Let's write some utility functions to visualize the bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfaf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import numpy as np \n",
    "from PIL import Image, ImageDraw\n",
    "from pydantic import BaseModel, confloat, conint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e46d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bbox(BaseModel):\n",
    "    # Bbox placeholder\n",
    "    xmin: confloat(ge=0)\n",
    "    ymin: confloat(ge=0)\n",
    "    xmax: confloat(ge=0)\n",
    "    ymax: confloat(ge=0)\n",
    "    \n",
    "    @property\n",
    "    def ctr(self):\n",
    "        xctr = self.xmin + (w/2)\n",
    "        yctr = self.ymin + (h/2)\n",
    "        return np.asarray([xctr, yctr, self.w, sel.h]).reshape(1, -1)\n",
    "    \n",
    "    @property\n",
    "    def area(self):\n",
    "        return self.w * self.h\n",
    "    \n",
    "    @property\n",
    "    def w(self):\n",
    "        return (self.xmax-self.xmin)\n",
    "    \n",
    "    @property\n",
    "    def h(self):\n",
    "        return (self.ymax-self.ymin)\n",
    "    \n",
    "    @property\n",
    "    def corner(self):\n",
    "        return np.asarray([self.xmin, self.ymin, self.xmax, self.ymax]).reshape(1, -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a881e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(np.uint8(np.zeros((200, 200, 3))))\n",
    "gt_bbox = Bbox(xmin=80, ymin=80, xmax=120, ymax=120)\n",
    "pred_bbox = [Bbox(xmin=140, ymin=140, xmax=180, ymax=180), Bbox(xmin=90, ymin=90, xmax=130, ymax=130)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff52804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img: Image, bbox: np.asarray, color:str=\"green\"):\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    for b in bbox:\n",
    "        img1.rectangle([(b.xmin, b.ymin), (b.xmax, b.ymax)], outline=color, width=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20adcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image= draw(image, [gt_bbox], color=\"green\")\n",
    "image= draw(image, pred_bbox, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356f827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAABrUlEQVR4nO3dwWrCQBRAUVv64fPn7U4KDSLWO0km56xExQS5vEBixtsNAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADofe+/AdOOSm57uc+8dYE3CIvG19w7sZyy3oSMxsUgIi4SwSAiLhLBICIvEhU83bPkuPnQ89a7FroGYWCSERcKhcNs7D0zjz4NfkoPvAZhYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSEReLCN6yOh09uvsrTTCwSwiKx2OI5/3VfSWHa9zJ/i3OYWCSERUJYJIRFQlgkhEXiwmfeH1p1BcdpTCwSwgIAAAAAgHda7Aexa9rxwuXLfbikQ0JYJPxs5kzm3zv0MhOLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEhYKvJMTvS/ryYWCWEBAAAAAAAAAAAAAHBUPxgfDcIyKoGNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x200>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c5d92",
   "metadata": {},
   "source": [
    "## IoU\n",
    "IoU is used as a metric to decide if a predicted bbox is TP or FP. (1-IOU) can be used as loss as \n",
    "- non-negativity: it is always positive value [0-1], minimum value is 0, when gt and pred bbox overlap 100%.\n",
    "- symmetry\n",
    "- traingle inequality\n",
    "- identity of indiscernibles\n",
    "\n",
    "IoU is defined as intersection between two boxes by union of the two boxes. \n",
    "\n",
    "$$\n",
    "IoU = \\frac{(A \\cap B)}{(A \\cup B)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "IoU_{loss} = 1- IOU\n",
    "$$\n",
    "\n",
    "The main drawback with IoU is that the loss is zero when both the boxes have no intersection, means IoU metric cannot distinguish between two boxes which are really far from each other and which are in close by vicinity (but dont overlap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "662b70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3913]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox1 = torch.from_numpy(gt_bbox.corner)\n",
    "bbox2 = torch.vstack([torch.from_numpy(t.corner) for t in pred_bbox])\n",
    "print(bbox1.shape, bbox2.shape)\n",
    "iou=torchvision.ops.box_iou(bbox1, bbox2)\n",
    "iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edaf314",
   "metadata": {},
   "source": [
    "## GIOU\n",
    "Generalized IoU solves the problem with IoU by adding a penalty term to the original IoU loss as below\n",
    "\n",
    "$$\n",
    "GIoU = IoU - \\frac{(C \\backslash A \\cup B)}{C}\n",
    "$$\n",
    "\n",
    "where C is the closest convex shape which contain both A and B (as shown in the figure below). Here, since A and B are rectangle we will choose C shape also to be rectangle\n",
    "\n",
    "The penality term is defined as the ratio between the area occupied by C excluding A and B and divide by the total area occupied by C\n",
    "\n",
    "using torchvision, we can calculate the `generalized_box_iou` as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b33adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6800,  0.3113]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giou=torchvision.ops.generalized_box_iou(bbox1, bbox2)\n",
    "giou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e256934",
   "metadata": {},
   "source": [
    "### pointers on GIoU\n",
    "- The range is between -1, 1. incase of loss this is betwen (0, 2) as loss is defined as (1-GIoU). \n",
    "- GIoU loss ranges from (0, 2), so we can use this as a loss function for bbox regression\n",
    "- GIoU has non-zero loss for non-overlapping boxes, hence non-zero gradient and better optimization\n",
    "- GIoU loss reduces as two bboxes comes closer as the overall C tends to A$\\cup$B, this again helps in better optimization\n",
    "- when one bbox is inside another, C becomes the same as A$\\cup$B  and hence zero. then GIoU is same as IoU\n",
    "- For Pred box 1, since there is no intersection, IoU is zero and hence it is -ve.\n",
    "- For pred box 2, since there is interaction, IoU value is non-zero and hence we have a +ve value. \n",
    "\n",
    "\n",
    "Sudo alogrithm for GIoU\n",
    "- take b1 & b2 boxes for which you want to calculate IoU\n",
    "- find closest bbox which contains both b1 and b2\n",
    "- calculate b1 intersection b2 area - [3]\n",
    "- calculatate b1 union b2 area = (b1 area + b2 area - b1 intersection b2) - [4]\n",
    "- calulate iou = [3]/[4] - [5]\n",
    "- calculate C area - [6]\n",
    "- calculate GIoU = [5] - ([6] - [4])/[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd3cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_convex_bbox(b1, b2):\n",
    "    xmin = min([b1.xmin, b2.xmin])\n",
    "    xmax = max([b1.xmax, b2.xmax])\n",
    "    ymin = min([b1.ymin, b2.ymin])\n",
    "    ymax = max([b1.ymax, b2.ymax])\n",
    "    return Bbox(xmin=xmin, ymin=ymin, xmax=xmax, ymax=ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a93cc7",
   "metadata": {},
   "source": [
    "> visualize C bbox with b1 and b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986a6604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAABoUlEQVR4nO3dMQ6CQBQAUTEe3JtjY2dhBAfY7HuVBcWPmXxoWG43AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOgsZw9wtHU9e4KhLFsDuf91DHgTFonH2QOcZvOS/9nz48fl7X9gsLFICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi8S8R0UOdHDjiGwsEsIiMe8HBI47NXlA+/8lG4uEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBITPyWzjjW75dcjo1FQlgk3ApHctiLRftvvjYWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZGY96jIdcCziAca2cYiISwAAAAAAAAAAAAAAK7qBSsTD0+nQynsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x200>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cbbox = closest_convex_bbox(gt_bbox, pred_bbox[0])\n",
    "image = Image.fromarray(np.uint8(np.zeros((200, 200, 3))))\n",
    "image= draw(image, [gt_bbox], color=\"green\")\n",
    "image= draw(image, [pred_bbox[0]], color=\"red\")\n",
    "image= draw(image, [Cbbox], color=\"yellow\")\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91852f8",
   "metadata": {},
   "source": [
    "> yellow was C bbox  \n",
    "> red and green our pair of bbox which are of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a89f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_iou(bbox1, bbox2):\n",
    "    x1 = max(bbox1.xmin, bbox2.xmin)\n",
    "    y1 = max(bbox1.ymin, bbox2.ymin)\n",
    "    x2 = min(bbox1.xmax, bbox2.xmax)\n",
    "    y2 = min(bbox1.ymax, bbox2.ymax)\n",
    "    intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f3ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.68"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou = intersect_iou(gt_bbox, pred_bbox[0])\n",
    "AUB = gt_bbox.area + pred_bbox[0].area - iou\n",
    "giou = iou - ((Cbbox.area - AUB)/Cbbox.area)\n",
    "giou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a056e72",
   "metadata": {},
   "source": [
    "> The obtained iou is similar as GIoU we got from `torchvision`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe33b95",
   "metadata": {},
   "source": [
    "## DIoU\n",
    "- In the paper [Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression](https://arxiv.org/abs/1911.08287), authors have pointed out several problems with GIoU\n",
    "- GIoU loss will totally degrade to IoU loss for enclosing bounding box.\n",
    "- Due to heavily relaying on IoU term, GIoU needs more time for optimization (found empherically in the paper)\n",
    "- it doesnt work well (or need more iterations) for vertical and horizontal bounding boxes (found through simulation in paper)\n",
    "\n",
    "The DIOU loss instead tries to converge on the distance between the two center points of ground truth and predicted bounding box. \n",
    "\n",
    "$$\n",
    "R_{DIOU} = \\frac{\\rho^2(b, b^{gt})}{c^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "L_{DIoU} = 1 - IOU + R_{DIOU}\n",
    "$$\n",
    "\n",
    "- where $\\rho(.)$ is the eculidean distance between b and $b^{gt}$\n",
    "- c is the diagonal length of the samllest enclosing box covering the two boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0df2a20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3600,  0.3513]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diou=torchvision.ops.distance_box_iou(bbox1, bbox2)\n",
    "diou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db15a0",
   "metadata": {},
   "source": [
    "> iou is same before   \n",
    "> calculate the penalty term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ee7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_between_centers(b1, b2):\n",
    "    b1x = b1.xmin + (b1.w/2)\n",
    "    b1y = b1.ymin + (b1.h/2)\n",
    "    b2x = b2.xmin + (b2.w/2)\n",
    "    b2y = b2.ymin + (b2.h/2)\n",
    "    return ((b2y-b1y)**2) + ((b2x-b1x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "443e3479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho = euclidean_distance_between_centers(gt_bbox, pred_bbox[0])\n",
    "c_sqr = ((Cbbox.xmax-Cbbox.xmin)**2) + ((Cbbox.ymax-Cbbox.ymin)**2)\n",
    "diou_penalty = rho/c_sqr \n",
    "diou_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef984499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3599999999999999"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diou = 1+ iou - l_diou\n",
    "diou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7396b",
   "metadata": {},
   "source": [
    "## CIOU\n",
    "Also called as CIOU and mentioned in the same paper as DIOU, C stands for Complete. Where in DIOU we have considered distance between two boxes via penalty term and iou between two boxes as iou term, compelete iou also adds penalty on aspect ratio also.\n",
    "\n",
    "$$\n",
    "R_{CIoU} = \\frac{\\rho^2(b, b^{gt})}{c^2} + \\alpha v.\n",
    "$$\n",
    "\n",
    "where $R_{CIoU}$ is the penalty term for CIOU\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{v}{(1-IoU+v)}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the positive trade-off parameter.\n",
    "\n",
    "$$\n",
    "v = \\frac{4}{\\pi^2} (\\arctan\\frac{w^{gt}}{h^{gt}} - \\arctan\\frac{w}{h})^2\n",
    "$$\n",
    "\n",
    "where v measures the consitency of aspect ratio\n",
    "\n",
    "$$\n",
    "L_{CIoU}= 1 - IoU + R_{CIoU}\n",
    "$$\n",
    "\n",
    "where $L_{CIoU}$ is the complete loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbe35e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3600,  0.3513]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciou=torchvision.ops.complete_box_iou(bbox1, bbox2)\n",
    "ciou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d5696",
   "metadata": {},
   "source": [
    "> it is same as DIOU as both our bbox1 aspect ratio and the bbox2 aspect ratio is same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978eaf5",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Looking at various algorithms The performance of `CIoU (10% AP75, 6%AP) > DIoU (6% AP75, 4%AP) > GIoU (5% AP75, 2%AP)> IoU`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
