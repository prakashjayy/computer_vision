{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e571c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b9e2f",
   "metadata": {},
   "source": [
    "VGG has plain (single path) conv layers unlike ResNets which have residual layers(multi-path). Discussion on [`RepVGG: Making VGG-style ConvNets Great Again`](https://arxiv.org/pdf/2101.03697.pdf).\n",
    "\n",
    "\n",
    "### VGG\n",
    "$$\n",
    "y = f(x)\n",
    "$$\n",
    "\n",
    "### ResNet \n",
    "$$\n",
    "y = f(x)+x \n",
    "$$\n",
    "\n",
    "\n",
    "> 1. multi-path networks has more memory requirement than single-path networks \n",
    "\n",
    "In case of `VGG` we just need to one variable at a time. x when passed to function `f` gives output of y.In `Resnet` we need to store x and then f(x) also (memory required is double) in memory, Later add both of them to get y. \n",
    "\n",
    "\n",
    "> 2. Even though multi-path networks have lesser number of `FLOPs`, they take more time compared to single path network\n",
    "\n",
    "in the above scenerio, though addition is simple, `Memory access cost` is significant. Also a network with few large operators achieve high `data parallelism` than a network with large small operators (inception, Efficientnet) etc. \n",
    "\n",
    "\n",
    "Considering the above two cases, we feel that `VGG` like architectures are more efficient than `ResNet`. This is partially true but when trained on `ImageNet`, ResNet outperforms VGG, this is because of `vanishing gradient problem` discussed [here](https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624)\n",
    "\n",
    "\n",
    "So is there a way we can achieve `ResNet` like performance with `VGG` kind of architecuture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49afc73",
   "metadata": {},
   "source": [
    "### Fusing Multi-path `ResNet` architecuture during training to Single-path architecture during inference.\n",
    "\n",
    "Lets take a ResNet like conv block. \n",
    "\n",
    "It applies three conv layers with Batch norm parallelly on input and adds all the inputs together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063425a4",
   "metadata": {},
   "source": [
    "> 1. input tensor x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870162dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 10, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((3, 24, 10, 10))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a9156",
   "metadata": {},
   "source": [
    "> create conv and batch norm layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22218213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(24, 24, kernel_size=(3,3), padding=1, bias=False)\n",
    "conv2 = nn.Conv2d(24, 24, kernel_size=(1,1), bias=False)\n",
    "conv3 = nn.Conv2d(24, 24, kernel_size=(3,3), stride=(1, 1), padding=1, bias=False)\n",
    "conv3.weight.data.fill_(0)\n",
    "for i in range(conv3.weight.data.shape[0]):\n",
    "    conv3.weight.data[i, i, 1, 1] = 1\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82773e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = nn.BatchNorm2d(24)\n",
    "bn2 = nn.BatchNorm2d(24)\n",
    "bn3 = nn.BatchNorm2d(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4dc50",
   "metadata": {},
   "source": [
    "### Conv3 is just an identity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a2eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 10, 10])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = conv3(x)\n",
    "    print(y.shape)\n",
    "    print(torch.allclose(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfecc0c",
   "metadata": {},
   "source": [
    "> Perform the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afde0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 10, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y1 = bn1(conv1(x))\n",
    "    y2 = bn2(conv2(x))\n",
    "    y3 = bn3(conv3(x))\n",
    "    y_unfused = y1+y2+y3\n",
    "    print(y_unfused.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd8964",
   "metadata": {},
   "source": [
    "### Fusing mutli-paths into single conv layer. \n",
    "Here we need to do two kinds of fusing.\n",
    "- Fuse conv layer and batchnorm \n",
    "- fuse parallel conv layer. \n",
    "\n",
    "Mathematically this is what happens when we apply both the transforms one after the other.\n",
    "\n",
    "$$\n",
    "y' = I*W  \n",
    "$$\n",
    "\n",
    "$$\n",
    "y'' = BN(y')\n",
    "$$\n",
    "\n",
    "where, \n",
    "$$\n",
    "BN(y') = (y' - \\mu) * (\\gamma/\\sigma) +  \\beta\n",
    "$$\n",
    "\n",
    "we can rewrite this as \n",
    "$$\n",
    "out = I* (W)(\\gamma/\\sigma) + ( - (\\mu \\gamma/\\sigma) + \\beta )\n",
    "$$\n",
    "\n",
    "we will keep \n",
    "$$\n",
    "bias = - (\\mu \\gamma/\\sigma) + \\beta\n",
    "$$\n",
    "\n",
    "then new `weight` \n",
    "$$\n",
    "W' = (W)(\\gamma/\\sigma)\n",
    "$$\n",
    "\n",
    "so finally we have \n",
    "\n",
    "$$\n",
    "out = I*W' + bias\n",
    "$$\n",
    "\n",
    "Lets do this using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af66c541",
   "metadata": {},
   "source": [
    "### Fusing conv layer + batchnorm \n",
    "here we will fuse conv1 + bn1 to `conv1_fused`. Function is copied from [here](https://gist.githubusercontent.com/FrancescoSaverioZuppichini/42056dee938e5c694d5ea3caca64833f/raw/ad0af226916720dc3baa7a61cc52bf91fbbc8bee/repvgg-5.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df72d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fused_bn_to_conv_state_dict(\n",
    "    conv: nn.Conv2d, bn: nn.BatchNorm2d\n",
    "):\n",
    "    # in the paper, weights is gamma and bias is beta\n",
    "    bn_mean, bn_var, bn_gamma, bn_beta = (\n",
    "        bn.running_mean,\n",
    "        bn.running_var,\n",
    "        bn.weight,\n",
    "        bn.bias,\n",
    "    )\n",
    "    # we need the std!\n",
    "    bn_std = (bn_var + bn.eps).sqrt()\n",
    "    # eq (3)\n",
    "    conv_weight = nn.Parameter((bn_gamma / bn_std).reshape(-1, 1, 1, 1) * conv.weight)\n",
    "    # still eq (3)\n",
    "    conv_bias = nn.Parameter(bn_beta - bn_mean * bn_gamma / bn_std)\n",
    "    return {\"weight\": conv_weight, \"bias\": conv_bias}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b873be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_bn = nn.Sequential(\n",
    "    conv1,\n",
    "    bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76d17e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # be sure to switch to eval mode!!\n",
    "    conv1_bn = conv1_bn.eval()\n",
    "    \n",
    "    # create a fused layer. \n",
    "    conv1_fused = nn.Conv2d(24, 24, kernel_size=(3,3), padding=1, bias=True)\n",
    "    conv1_fused.load_state_dict(get_fused_bn_to_conv_state_dict(conv1_bn[0], conv1_bn[1]))\n",
    "    \n",
    "    print(torch.allclose(conv1_fused(x), conv1_bn(x), atol=1e-5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35c9fb",
   "metadata": {},
   "source": [
    "### Converting a 1x1 conv layer to 3x3 conv layer and getting the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3443f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weight\n"
     ]
    }
   ],
   "source": [
    "conv2_3x3 = nn.Conv2d(24, 24, kernel_size=(3,3), bias=False, padding=1)\n",
    "conv2_3x3.load_state_dict({\"weight\": torch.nn.functional.pad(conv2.weight.data, [1, 1, 1, 1])})\n",
    "print(\"Loaded weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b44417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = conv2(x)\n",
    "    print(torch.allclose(y, conv2_3x3(x), atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e740e1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "There are three major operations we performed and checked. \n",
    "- we can fuse Conv layer + BatchNorm into single layer. \n",
    "- we can convert a 1x1 conv layer to 3x3 conv layer with padding=1.\n",
    "- We can create an identity layer with 3x3 conv layer. \n",
    "\n",
    "So if we perform the computation in `ResNet` wise or `VGG` style, we will get the same output. For the same reason, we can train the network in `ResNet` style and do inference in `VGG` style. \n",
    "\n",
    "Note: padding and bias are set according to output needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
