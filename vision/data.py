# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_data.ipynb.

# %% auto 0
__all__ = ['VOC_CLASSES', 'voc_xml_annot_2_bbox_cat', 'image_grid', 'thumbnail', 'VOCDataset', 'load_data']

# %% ../nbs/00_data.ipynb 2
import torch
import PIL 
import numpy as np 
import xml.etree.ElementTree as ET

from PIL import Image

# %% ../nbs/00_data.ipynb 8
VOC_CLASSES = ["person", "bird", "cat", "cow", "dog", "horse", "sheep", \
               "aeroplane", "bicycle", "boat", "bus", "car", "motorbike", "train", \
               "bottle", "chair", "diningtable", "pottedplant", "sofa", "tvmonitor"]

# %% ../nbs/00_data.ipynb 10
def voc_xml_annot_2_bbox_cat(xml_loc):
    "code copied with slight changes from `https://stackoverflow.com/questions/53317592/reading-pascal-voc-annotations-in-python`"
    xml_root = ET.parse(xml_loc).getroot()
    bboxes, cats = [], []
    for boxes in xml_root.iter('object'):
        cat = boxes.find("name").text
        bbox = [int(boxes.find(f"bndbox/{i}").text) for i in ["xmin", "ymin", "xmax", "ymax"]]
        bboxes.append(bbox)
        cats.append(cat)
    cat_ids = np.asarray([VOC_CLASSES.index(i)+1 for i in cats])
    return np.asarray(bboxes), cat_ids, cats

# %% ../nbs/00_data.ipynb 14
def image_grid(imgs, rows, cols):
    #from fastai course2
    if not isinstance(imgs[0], PIL.Image.Image): imgs = [Image.fromarray(img) for img in imgs]
    w,h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

# %% ../nbs/00_data.ipynb 15
def thumbnail(img, size=128):
    if not isinstance(img, PIL.Image.Image): img = Image.fromarray(img)
    w, h = img.size
    ar = h/w 
    return img.resize((size, int(size*ar)))

# %% ../nbs/00_data.ipynb 19
class VOCDataset(torch.utils.data.Dataset):
    def __init__(self, root: str, train: bool=True, transforms=None):
        self.root=root
        self.transforms = transforms 
        self.train = train
        self.ids = (root/f"ImageSets/Main/{'train' if train else 'val'}.txt").read_text().rsplit("\n")
    
    def __getitem__(self, idx):
        img_dict = {}
        idx = self.ids[idx] if isinstance(idx, int) else idx 
        img = Image.open(self.root / "JPEGImages" / f"{idx}.jpg")
        img_dict["img"] = np.asarray(img)
        bbox, cat_ids, cats = voc_xml_annot_2_bbox_cat(self.root / "Annotations" / f"{idx}.xml")
        img_dict["bbox"] = bbox 
        img_dict["cat_ids"] = cat_ids
        img_dict["cats"] = cats
        if self.transforms is not None: return self.transforms(img_dict) 
        return img_dict
        
    def __len__(self): return len(self.ids)  

# %% ../nbs/00_data.ipynb 20
def load_data(name, **kwargs):
    if name=="voc": return VOCDataset(**kwargs)
    else: raise NotImplementedError("only voc is implemented")
