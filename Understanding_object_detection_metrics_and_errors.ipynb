{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e61445f",
   "metadata": {},
   "source": [
    "## Object detection metrics and errors \n",
    "Object detection and instance segmentation primarily use one metric to judge performance: `mean Average Precision (mAP )`. How do we interpret it? For a metric like `accuracy` we know that 90% means that the model is wrong `10%` of the time. we will see the following things in this blog.\n",
    "- what does a mAP of `63.2%` actually mean? \n",
    "- why do we use `mAP` as a metric in object detection? \n",
    "- what kind of errors are associated with your model which is hampering your overall score?\n",
    "    - A `false positive` can be a \n",
    "        - duplicate detection\n",
    "        - misclassification\n",
    "        - mislocalization\n",
    "        - confusion with background\n",
    "        - both a misclassification and mislocalization.\n",
    "    - a false negative could be a \n",
    "        - completely missed ground truth, \n",
    "        - potentially correct prediction could have just been misclassified or mislocalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97995983",
   "metadata": {},
   "source": [
    "There are 3 places our detector can affect mAP \n",
    "- outputting false positives during the matching step, \n",
    "- not outputting true positives (i.e., false negatives) for computing recall, \n",
    "- having incorrect calibration (i.e., outputting a higher confidence for a false positive then a true positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684ae92",
   "metadata": {},
   "source": [
    "The difficulty of the code has increased because\n",
    "- we have multiple classes \n",
    "- we have multiple thresholds \n",
    "- we have to do for both mask and bbox\n",
    "- we have multiple metrics [small, medium, large, mAR, mAP]\n",
    "\n",
    "\n",
    "we will simplify the code by \n",
    "- using one single threshold (mAP 50)\n",
    "- only bbox \n",
    "- only mAP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f889a8",
   "metadata": {},
   "source": [
    "First lets calculate `mAP` of the model. we will First use `torchvision` retinanet on COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffee100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.ops.boxes import _box_xywh_to_xyxy as xywh_to_xyxy\n",
    "from typing import Union, Optional, List\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08831cc4",
   "metadata": {},
   "source": [
    "> Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d5becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.detection.retinanet.RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn_v2(weights = weights, num_classes=91)\n",
    "model.eval()\n",
    "preprocess= weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed320099",
   "metadata": {},
   "source": [
    "> Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "62aa9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bbox(BaseModel):\n",
    "    x1: float \n",
    "    y1: float \n",
    "    x2: float \n",
    "    y2: float \n",
    "    \n",
    "    @property\n",
    "    def xyxy(self):\n",
    "        return np.asarray([self.x1, self.y1, self.x2, self.y2])\n",
    "    \n",
    "    @property\n",
    "    def xywh(self):\n",
    "        x, y = self.x1, self.y1\n",
    "        h = self.y2-self.y1\n",
    "        w = self.x2-self.x1\n",
    "        return np.asarray([x, y, w, h])\n",
    "    \n",
    "\n",
    "\n",
    "class AnnotBbox(BaseModel):\n",
    "    img_id: int\n",
    "    category_id: int\n",
    "    bbox: Bbox\n",
    "    conf: Optional[float]\n",
    "    iou: Optional[float]\n",
    "    tp_fp_fn: Optional[str]\n",
    "    area: Optional[float]\n",
    "    is_crowd: Optional[int]\n",
    "    chars: Optional[List[str]]\n",
    "        \n",
    "        \n",
    "class AnnotImg(BaseModel):\n",
    "    img_id: int \n",
    "    gt_box: List[AnnotBbox] = []\n",
    "    pred_box: List[AnnotBbox] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e999a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset:\n",
    "    def __init__(self, img_root, annot_loc, transforms=None):\n",
    "        self.coco = COCO(annot_loc)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.img_ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta = self.coco.imgs[img_id]\n",
    "        img_loc = self.img_root / img_meta[\"file_name\"]\n",
    "        img = Image.open(img_loc)\n",
    "        \n",
    "        ## Load annotations \n",
    "        annot_ids = self.coco.getAnnIds(imgIds=[img_id])\n",
    "        annots = self.coco.loadAnns(ids = annot_ids)\n",
    "        annot = []\n",
    "        for ann in annots:\n",
    "            box = ann[\"bbox\"]\n",
    "            box = Bbox(x1=box[0], y1=box[1], x2=box[2]+box[0], y2=box[3]+box[1])\n",
    "            tt = AnnotBbox(img_id=img_id, category_id=ann[\"category_id\"], bbox=box)\n",
    "            annot.append(tt)\n",
    "        annot = AnnotImg(img_id=img_id, gt_box=annot)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            return self.transforms(img).unsqueeze(0), annot\n",
    "        return img, annot\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.coco.imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cb26427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annot_loc = \"data/coco/annotations/instances_val2017.json\"\n",
    "img_root = \"data/coco/val2017/\"\n",
    "ds = COCODataset(img_root, annot_loc=annot_loc, transforms=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86783c2",
   "metadata": {},
   "source": [
    "> Load a single image with its annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7c093cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296649 torch.Size([1, 3, 427, 640]) 26\n"
     ]
    }
   ],
   "source": [
    "img, annots = ds[10]\n",
    "img_id = annots.img_id\n",
    "print(img_id, img.shape, len(annots.gt_box))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7566ad1",
   "metadata": {},
   "source": [
    "> Generate predictions\n",
    "\n",
    "- This model uses an nms threshold of 0.5. check `model.nms_thresh`\n",
    "- The output is a dict with boxes, scores, labels as keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b82496f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes', 'scores', 'labels'])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(img)[0]\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3a5492e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_outputs_to_annotschema(output, img_id):\n",
    "    preds = []\n",
    "    for box, score, label in zip(output[\"boxes\"], output[\"scores\"], output[\"labels\"]):\n",
    "        tt = AnnotBbox(img_id=img_id, bbox=Bbox(x1=box[0], y1=box[1], x2=box[2], y2=box[3]), conf=round(float(score), 3), category_id=int(label))\n",
    "        preds.append(tt)\n",
    "    return preds\n",
    "annots.pred_box = convert_outputs_to_annotschema(output, img_id)\n",
    "len(annots.pred_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "388da3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnotBbox(img_id=296649, category_id=4, bbox=Bbox(x1=262.2518005371094, y1=329.0896911621094, x2=427.1844177246094, y2=427.0000305175781), conf=0.879, iou=None, tp_fp_fn=None, area=None, is_crowd=None, chars=None)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots.pred_box[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c942558",
   "metadata": {},
   "source": [
    "## check FP's, FN's and TP's for each bbox.\n",
    "Each bbox (both gt and pred), we need to assign TP, FP or FN label. We will do this at 3 levels\n",
    "- single image single class `SISCE` \n",
    "- single image all classes `SIE`\n",
    "- Dataset level `DE`\n",
    "where `E` stands for Error. \n",
    "\n",
    "### SISCE: single image, single class\n",
    "- this works on single image and for a single class.\n",
    "- It calculates IOU between gt and pred of the same class bboxes. \n",
    "- For gt, it assigns TP or FN label\n",
    "- For preds, it assigns TP or FP label.\n",
    "- creats gt and preds df with scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e06d4",
   "metadata": {},
   "source": [
    "> for each predicted bounding box we need to see if it has a correct match or not. we will do this for each class in each image first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1e534",
   "metadata": {},
   "source": [
    "> find iou between gt and pred and assign each pred with a gt using max_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "333626cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignTPFPTN:\n",
    "    def __init__(self, iou_thr, iou_type=\"iou\", allow_duplicates=False):\n",
    "        self.iou_thr = iou_thr\n",
    "        self.iou_type = iou_type\n",
    "        self.allow_duplicates = allow_duplicates \n",
    "        self.all_matches = np.empty((0, 3))\n",
    "    \n",
    "    def implement_iou(self, gt: List[AnnotBbox], pred: List[AnnotBbox]):\n",
    "        gt = np.vstack([i.bbox.xyxy for i in gt])\n",
    "        pred = np.vstack([i.bbox.xyxy for i in pred])\n",
    "        \n",
    "        if self.iou_type == \"iou\":\n",
    "            return torchvision.ops.box_iou(torch.Tensor(gt).float(), torch.Tensor(pred).float()).numpy()\n",
    "        else:\n",
    "            raise NotImplementedError(f\"iou_type: {self.iou_type} is not implemented\")\n",
    "    \n",
    "    def match_idx_for_each_gt(self, gt: List[AnnotBbox], pred: List[AnnotBbox]):\n",
    "        # Get one unique match for each gt. \n",
    "        self.all_matches = np.empty((0, 3))\n",
    "        run = self._base_checks(gt, pred)\n",
    "        if run:\n",
    "            iou = self.implement_iou(gt, pred)\n",
    "            widx = np.where(iou > self.iou_thr)\n",
    "            all_matches = np.asarray([(widx[0][i], widx[1][i], iou[widx[0][i], widx[1][i]]) for i in range(widx[0].shape[0])])\n",
    "\n",
    "            # if there is match\n",
    "            if all_matches.shape[0] > 0:  \n",
    "                # sort by prob\n",
    "                all_matches = all_matches[all_matches[:, 2].argsort()[::-1]] \n",
    "                #if there one prediction for 2 gts. Remove the 1 with low conf\n",
    "                all_matches = all_matches[np.unique(all_matches[:, 1], return_index=True)[1]] \n",
    "                # sort again via prob score. \n",
    "                all_matches = all_matches[all_matches[:, 2].argsort()[::-1]] \n",
    "                # if a gt has two predictions, remove the 1 with low confidence.\n",
    "                # below code should not run when we allow duplicate for each gt. \n",
    "                if not self.allow_duplicates:\n",
    "                    all_matches = all_matches[np.unique(all_matches[:, 0], return_index=True)[1]] \n",
    "            self.all_matches = all_matches \n",
    "    \n",
    "    def _base_checks(self, gt, pred):\n",
    "        if (len(gt) == 0) or (len(pred) == 0):\n",
    "            return False\n",
    "        if (len(gt) == 0) and (len(pred) ==0):\n",
    "            return False \n",
    "        return True\n",
    "    \n",
    "    def assign_label_to_gt(self, gt):\n",
    "        if len(gt) == 0:\n",
    "            return gt\n",
    "        pos_idx = np.unique(self.all_matches[:, 0]).astype(int)\n",
    "        for g in gt:\n",
    "            g.tp_fp_fn = \"FN\"\n",
    "                \n",
    "        for pos in pos_idx:\n",
    "            gt[pos].tp_fp_fn = \"TP\"\n",
    "        return gt\n",
    "    \n",
    "    def assign_label_to_pred(self, pred):\n",
    "        if len(pred) == 0:\n",
    "            return pred \n",
    "        pos_idx = self.all_matches[:, 1].astype(int)\n",
    "        iou_score = self.all_matches[:, 1]\n",
    "        \n",
    "        for g in pred:\n",
    "            g.tp_fp_fn = \"FN\"\n",
    "            g.iou = 0\n",
    "        \n",
    "        for num, pos in enumerate(pos_idx):\n",
    "            pred[pos].tp_fp_fn = \"TP\"\n",
    "            pred[pos].iou = iou_score[num]\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    def __call__(self, img: AnnotImg, cat_id=1):\n",
    "        self.all_matches = np.empty((0, 3))\n",
    "        gt = [i for i in img.gt_box if i.category_id == cat_id]\n",
    "        pred = [i for i in img.pred_box if i.category_id == cat_id]\n",
    "        self.match_idx_for_each_gt(gt, pred)\n",
    "        gt = self.assign_label_to_gt(gt)\n",
    "        pred = self.assign_label_to_pred(pred)\n",
    "        new_img = AnnotImg(img_id=img.img_id, gt_box=gt, pred_box=pred)\n",
    "        return new_img\n",
    "    \n",
    "#     def create_df(self, gt, pred, scores):\n",
    "#         gt = self.forward(gt, pred)\n",
    "#         gt_df = self.to_df(gt, gt_labels)\n",
    "#         pred_df = self.to_df(pred, pred_labels)\n",
    "#         pred_df[\"conf_scores\"] = scores\n",
    "#         pred_df['iou_scores'] = iou_scores \n",
    "#         return gt_df, pred_df\n",
    "    \n",
    "    \n",
    "#     def to_df(self, c1, c1_tt):\n",
    "#         if isinstance(c1, torch.Tensor):\n",
    "#             c1 = c1.numpy()\n",
    "#         df = pd.DataFrame(c1)\n",
    "#         df.columns = [\"x1\", \"y1\", \"x2\", \"y2\"]\n",
    "#         df[\"TP_FP_FN\"] = c1_tt\n",
    "#         return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fe93f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = AssignTPFPTN(0.3, allow_duplicates=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b577cd",
   "metadata": {},
   "source": [
    "> initally all matches are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "65ef4eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.all_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b66146",
   "metadata": {},
   "source": [
    "> then we create matches - allow_duplicates is optional , when true, each gt can have multiple predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "43ac7274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.match_idx_for_each_gt([], [])\n",
    "tt.all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f85cd60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 57)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_gt_boxes = [i for i in annots.gt_box if i.category_id == 1]\n",
    "req_pred_boxes = [i for i in annots.pred_box if i.category_id == 1]\n",
    "len(req_gt_boxes), len(req_pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "890e5113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.76189595],\n",
       "       [ 1.        ,  4.        ,  0.84801722],\n",
       "       [ 2.        ,  0.        ,  0.92562371],\n",
       "       [ 3.        ,  2.        ,  0.88024783],\n",
       "       [ 4.        ,  8.        ,  0.63157827],\n",
       "       [ 5.        ,  6.        ,  0.88249034],\n",
       "       [ 6.        , 10.        ,  0.8462857 ],\n",
       "       [ 7.        , 11.        ,  0.87101638],\n",
       "       [ 8.        , 13.        ,  0.77039939],\n",
       "       [ 9.        , 17.        ,  0.84931129],\n",
       "       [10.        ,  7.        ,  0.89239097],\n",
       "       [11.        ,  3.        ,  0.85208642],\n",
       "       [12.        ,  5.        ,  0.65539688]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.match_idx_for_each_gt(req_gt_boxes, req_pred_boxes)\n",
    "tt.all_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99440b3d",
   "metadata": {},
   "source": [
    "> Now assign labels to each gt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f8333274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_label = tt.assign_label_to_gt(req_gt_boxes)\n",
    "len(gt_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8b5ed",
   "metadata": {},
   "source": [
    "> Now assign labels to each pred. we can also get iou_scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6bcb9284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label = tt.assign_label_to_pred(req_pred_boxes)\n",
    "len(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "98214a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 13)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots_cat_1 = tt(annots, cat_id=1)\n",
    "len(annots_cat_1.pred_box), len(annots_cat_1.gt_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea6067",
   "metadata": {},
   "source": [
    "## Single class multiple images - mAP score. \n",
    "- mAP & mAR score can be aggregated for mulitple iou scores. \n",
    "- we should be able to subset bboxes (gt) based on small, medium, large. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097a0dc",
   "metadata": {},
   "source": [
    "## TODO: Lets use pydantic heavily in this. it will allow for better readability\n",
    "- we should store everything using pydantic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ce7e4",
   "metadata": {},
   "source": [
    "## this comes for per image at @iou_score\n",
    "- total true pos [per image]\n",
    "- total false pos [per image]\n",
    "- total false neg [per image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c20a9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\"Compute the average precision, given the recall and precision curves\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list)\n",
    "        precision: The precision curve (list)\n",
    "    # Returns\n",
    "        Average precision, precision curve, recall curve\n",
    "    \"\"\"\n",
    "\n",
    "    # Append sentinel values to beginning and end\n",
    "    mrec = np.concatenate(([0.0], recall, [recall[-1] + 0.01]))\n",
    "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
    "\n",
    "    # Compute the precision envelope\n",
    "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "\n",
    "    # Integrate area under curve\n",
    "    method = \"interp\"  # methods: 'continuous', 'interp'\n",
    "    if method == \"interp\":\n",
    "        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n",
    "        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate\n",
    "    else:  # 'continuous'\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n",
    "\n",
    "    return ap, mpre, mrec\n",
    "\n",
    "\n",
    "class mAP:\n",
    "    def __init__(self, iou_type, allow_duplicates=False):\n",
    "        self.iou_type = iou_type\n",
    "        self.allow_duplicates = allow_duplicates\n",
    "        self.raw: Dict[str, AnnotImg] = {}\n",
    "        self.gt_sc: Optional[pd.DataFrame] = None \n",
    "        self.pred_sc: Optional[pd.DataFrame] = None\n",
    "    \n",
    "    def update(self, img: AnnotImg):\n",
    "        # we need to predict and update the bboxes\n",
    "        self.raw[img.img_id] = img\n",
    "         \n",
    "    \n",
    "    def compute_map(self, cat_ids: List[int], topk: Optional[int]=None):\n",
    "        # compute ap for each class and then average them to get mAP\n",
    "        # top is used to take top N values if None, everything is used\n",
    "        pass \n",
    "    \n",
    "    def compute_ap_iou(self, iou_scores: List[float], cat_id: int,  topk: Optional[int]=None):\n",
    "        # compute AP @ multiple_ious @cat_id\n",
    "        aps = []\n",
    "        for iou_score in iou_scores:\n",
    "            self.compute_gt_pred_tpfpfn(iou_score, cat_id)\n",
    "            print(self.pred_sc.shape, self.gt_sc.shape)\n",
    "            ap, _ = self.compute_ap_iou_class(topk=topk)\n",
    "            aps.append(ap)\n",
    "        aps = np.asarray(aps)\n",
    "        return np.mean(aps), aps\n",
    "    \n",
    "    \n",
    "    def compute_ap_iou_class(self, topk: Optional[int]=None):\n",
    "        # compute AP@iou for a cat_id\n",
    "        if (self.gt_sc is None) or (self.pred_sc is None):\n",
    "            raise ValueError(\"Please call `comput_gt_pred_tpfptn first\")\n",
    "        gt, pred = self.gt_sc, self.pred_sc\n",
    "        total_gt = len(gt)\n",
    "        if topk is not None:\n",
    "            pred = pred.sort_values([\"img_id\", \"conf\"], ascending=False).reset_index(drop=True).groupby('img_id').head(topk)\n",
    "        gt, pred = self.cal_pre_rec(gt, pred)\n",
    "        ap, mpre, mrec = compute_ap(pred[\"recall\"].values, pred[\"precision\"].values)\n",
    "        return ap, {\"mpre\": mpre, \"mrec\": mrec, \"gt\": gt, \"pred\": pred}\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def cal_pre_rec(gt, pred):\n",
    "        total_gt = len(gt)\n",
    "        pred = pred.sort_values(\"conf\", ascending=False).reset_index(drop=True)\n",
    "        pred[\"TP\"] = pred[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"TP\" else 0)\n",
    "        pred[\"FP\"] = pred[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"FP\" else 0)\n",
    "        pred[\"acc_tp\"] = pred[\"TP\"].cumsum()\n",
    "        pred[\"acc_fp\"] = pred[\"FP\"].cumsum()\n",
    "        pred[\"precision\"] = pred[\"acc_tp\"] / (pred[\"acc_tp\"] + pred[\"acc_fp\"] + 1e-16)\n",
    "        pred[\"recall\"] = pred_conf[\"acc_tp\"] / (total_gt + 1e-16)\n",
    "        pred[\"AvgFalsePosScan\"] = pred_conf[\"acc_fp\"] / (total_gt + 1e-16)\n",
    "        return gt, pred\n",
    "    \n",
    "    \n",
    "    def compute_gt_pred_tpfpfn(self, iou_score, cat_id):\n",
    "        self.gt_sc = None \n",
    "        self.pred_sc = None \n",
    "        ttt = []\n",
    "        tp_fp_fn = AssignTPFPTN(iou_score, self.iou_type, self.allow_duplicates)\n",
    "        for img_id in self.raw.keys():\n",
    "            each_img = self.raw[img_id]\n",
    "            tt = tp_fp_fn(deepcopy(each_img), cat_id=cat_id)\n",
    "            ttt.append(tt)\n",
    "        gt_sc = pd.DataFrame([[i.img_id, i.tp_fp_fn] for img in ttt for i in img.gt_box])\n",
    "        gt_sc.columns = [\"img_id\", \"TP_FP_FN\"]\n",
    "        self.gt_sc = gt_sc\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        pred_sc = pd.DataFrame([[i.img_id, i.conf, i.tp_fp_fn] for img in ttt for i in img.pred_box])\n",
    "        pred_sc.columns = [\"img_id\", \"conf\", \"TP_FP_FN\"]\n",
    "        self.pred_sc = pred_sc\n",
    "        \n",
    "            \n",
    "        \n",
    "    def compute_mar(self, cat_ids: List[int], top: Optional[int]=None):\n",
    "        # compute ar for each class and then average them to get mAR\n",
    "        pass \n",
    "    \n",
    "    def compute_ar_iou(self, iou_scores=List[float], top: Optional[int]=None):\n",
    "        # compute AR @ multiple_ious \n",
    "        pass \n",
    "    \n",
    "    \n",
    "    def compute_ar_iou_class(self, iou_score, cat_id, top: Optional[int]=None):\n",
    "        # compute AR@iou for a cat_id\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b276d8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 6/5000 [01:24<19:34:16, 14.11s/it]\n"
     ]
    }
   ],
   "source": [
    "allt = []\n",
    "for d in tqdm(range(len(ds))):\n",
    "    img, annots = ds[d]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img)[0]\n",
    "        \n",
    "    preds = convert_outputs_to_annotschema(output, annots.img_id)\n",
    "    annots.pred_box = preds\n",
    "    allt.append(annots)\n",
    "    if d>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "45e1e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_score = mAP(\"iou\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "361145e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in allt:\n",
    "    map_score.update(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d33d57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_score.compute_gt_pred_tpfpfn(0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2808b079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19, 2),\n",
       "    img_id TP_FP_FN\n",
       " 0  397133       TP\n",
       " 1  397133       TP\n",
       " 2  252219       TP\n",
       " 3  252219       TP\n",
       " 4  252219       TP)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_score.gt_sc.shape, map_score.gt_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fcf4124d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 3),\n",
       "    img_id   conf TP_FP_FN\n",
       " 0  397133  0.834       TP\n",
       " 1  397133  0.662       TP\n",
       " 2  397133  0.125       FN\n",
       " 3  397133  0.115       FN\n",
       " 4  397133  0.102       FN)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_score.pred_sc.shape, map_score.pred_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "89108821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5 , 0.55, 0.6 , 0.65])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.5, 0.7, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "039cb8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 3) (19, 2)\n",
      "(154, 3) (19, 2)\n",
      "(154, 3) (19, 2)\n",
      "(154, 3) (19, 2)\n",
      "(154, 3) (19, 2)\n",
      "(154, 3) (19, 2)\n",
      "(154, 3) (19, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9523684210526316,\n",
       " array([0.95236842, 0.95236842, 0.95236842, 0.95236842, 0.95236842,\n",
       "        0.95236842, 0.95236842]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_score.compute_ap_iou(iou_scores=np.arange(0.5, 0.8, 0.05).tolist(), cat_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aa25f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397133\n",
      "37777\n",
      "252219\n",
      "87038\n",
      "174482\n",
      "403385\n",
      "6818\n"
     ]
    }
   ],
   "source": [
    "ttt = []\n",
    "for each_img in allt:\n",
    "    print(each_img.img_id)\n",
    "    tt = tp_fp_fn(deepcopy(each_img), cat_id=1)\n",
    "    ttt.append(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e608687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_sc = sum([len(i.gt_box) for i in ttt])\n",
    "gt_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a6a0fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP_FP_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TP_FP_FN\n",
       "0       TP\n",
       "1       TP\n",
       "2       FN\n",
       "3       FN\n",
       "4       FN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_sc = pd.DataFrame([[i.tp_fp_fn] for img in ttt for i in img.pred_box])\n",
    "gt_sc.columns = [\"TP_FP_FN\"]\n",
    "gt_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3265e6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 4, 22, 100, 17, 0, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i.pred_box) for i in ttt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da939835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conf</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>acc_tp</th>\n",
       "      <th>acc_fp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AvgFalsePosScan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.949</td>\n",
       "      <td>TP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.929</td>\n",
       "      <td>TP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.921</td>\n",
       "      <td>TP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.915</td>\n",
       "      <td>TP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.876</td>\n",
       "      <td>TP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     conf TP_FP_FN  TP  FP  acc_tp  acc_fp  precision    recall  \\\n",
       "36  0.949       TP   1   0       1       0        1.0  0.052632   \n",
       "14  0.929       TP   1   0       2       0        1.0  0.105263   \n",
       "15  0.921       TP   1   0       3       0        1.0  0.157895   \n",
       "16  0.915       TP   1   0       4       0        1.0  0.210526   \n",
       "37  0.876       TP   1   0       5       0        1.0  0.263158   \n",
       "\n",
       "    AvgFalsePosScan  \n",
       "36              0.0  \n",
       "14              0.0  \n",
       "15              0.0  \n",
       "16              0.0  \n",
       "37              0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_conf = pd.DataFrame([[i.conf, i.tp_fp_fn] for img in ttt for i in img.pred_box])\n",
    "pred_conf.columns = [\"conf\", \"TP_FP_FN\"]\n",
    "pred_conf = pred_conf.sort_values(\"conf\", ascending=False).reset_index(drop=True)\n",
    "pred_conf[\"TP\"] = pred_conf[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"TP\" else 0)\n",
    "pred_conf[\"FP\"] = pred_conf[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"FP\" else 0)\n",
    "pred_conf[\"acc_tp\"] = pred_conf[\"TP\"].cumsum()\n",
    "pred_conf[\"acc_fp\"] = pred_conf[\"FP\"].cumsum()\n",
    "pred_conf[\"precision\"] = pred_conf[\"acc_tp\"] / (pred_conf[\"acc_tp\"] + pred_conf[\"acc_fp\"] + 1e-16)\n",
    "pred_conf[\"recall\"] = pred_conf[\"acc_tp\"] / (gt_sc + 1e-16)\n",
    "pred_conf[\"AvgFalsePosScan\"] = pred_conf[\"acc_fp\"] / (gt_sc + 1e-16)\n",
    "pred_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d72eb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dcbb931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523684210526315"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap, mpre, mrec = compute_ap(pred_conf[\"recall\"].values, pred_conf[\"precision\"].values)\n",
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc067db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIE:\n",
    "    # Single image error\n",
    "    def __init__(self, iou_thr):\n",
    "        self.sisce = SISCE(iou_thr=iou_thr)\n",
    "    \n",
    "    def forward_class(self, \n",
    "                      gts: torch.Tensor, \n",
    "                      gt_labels: torch.Tensor, \n",
    "                      preds: torch.Tensor, \n",
    "                      pred_scores: torch.Tensor, \n",
    "                      pred_labels: torch.Tensor, \n",
    "                      req_label: int):\n",
    "        req_gt_boxes = gts[gt_labels ==req_label]\n",
    "        req_pred_boxes = preds[pred_labels == req_label]\n",
    "        req_pred_scores = pred_scores[pred_labels == req_label]\n",
    "        gt_df, pred_df = self.sisce.forward(req_gt_boxes, req_pred_boxes, req_pred_scores)\n",
    "        gt_df[\"label\"] = gt_labels[gt_labels == req_label].numpy()\n",
    "        pred_df[\"label\"] = pred_labels[pred_labels==req_label]\n",
    "        return gt_df, pred_df \n",
    "    \n",
    "    def forward(self, \n",
    "                gt: torch.Tensor, \n",
    "                gt_labels: torch.Tensor, \n",
    "                pred: torch.Tensor, \n",
    "                pred_score: torch.Tensor, \n",
    "                pred_labels: torch.Tensor,):\n",
    "        gts_df, preds_df = [], []\n",
    "        labels = torch.hstack([pred_labels, gt_labels]).unique()\n",
    "        for label in labels.unique():\n",
    "            gt_df, pred_df = self.forward_class(gt, gt_labels, pred, pred_score, pred_labels, req_label= label)\n",
    "            gts_df.append(gt_df)\n",
    "            preds_df.append(pred_df)            \n",
    "        return pd.concat(gts_df).reset_index(drop=True), pd.concat(preds_df).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04eceffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_error = SIE(iou_thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d9e7c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 6) (182, 8)\n"
     ]
    }
   ],
   "source": [
    "gts_df, preds_df = img_error.forward(gt_boxes, gt_labels, pred_boxes, pred_scores, pred_labels)\n",
    "print(gts_df.shape, preds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb52226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322.570007</td>\n",
       "      <td>290.809998</td>\n",
       "      <td>387.660004</td>\n",
       "      <td>418.429993</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.640015</td>\n",
       "      <td>292.109985</td>\n",
       "      <td>324.590027</td>\n",
       "      <td>421.759979</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.920000</td>\n",
       "      <td>266.880005</td>\n",
       "      <td>116.369995</td>\n",
       "      <td>422.669983</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424.119995</td>\n",
       "      <td>270.589996</td>\n",
       "      <td>531.589966</td>\n",
       "      <td>400.130005</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.269989</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>285.289978</td>\n",
       "      <td>316.100006</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  label\n",
       "0  322.570007  290.809998  387.660004  418.429993       TP    1.0\n",
       "1  273.640015  292.109985  324.590027  421.759979       TP    1.0\n",
       "2    1.920000  266.880005  116.369995  422.669983       TP    1.0\n",
       "3  424.119995  270.589996  531.589966  400.130005       TP    1.0\n",
       "4  259.269989  281.000000  285.289978  316.100006       TP    1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e965fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210682</td>\n",
       "      <td>265.643738</td>\n",
       "      <td>110.534225</td>\n",
       "      <td>422.256592</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.925624</td>\n",
       "      <td>0.875509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313.360962</td>\n",
       "      <td>284.719269</td>\n",
       "      <td>392.871094</td>\n",
       "      <td>421.843689</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.829786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429.111725</td>\n",
       "      <td>274.314087</td>\n",
       "      <td>533.618408</td>\n",
       "      <td>404.633026</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.880247</td>\n",
       "      <td>0.819460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494.161133</td>\n",
       "      <td>276.724335</td>\n",
       "      <td>586.270264</td>\n",
       "      <td>385.799164</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.852086</td>\n",
       "      <td>0.804641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.743530</td>\n",
       "      <td>291.526611</td>\n",
       "      <td>330.614044</td>\n",
       "      <td>415.199249</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.848018</td>\n",
       "      <td>0.783450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0    0.210682  265.643738  110.534225  422.256592       TP   0.925624   \n",
       "1  313.360962  284.719269  392.871094  421.843689       TP   0.761896   \n",
       "2  429.111725  274.314087  533.618408  404.633026       TP   0.880247   \n",
       "3  494.161133  276.724335  586.270264  385.799164       TP   0.852086   \n",
       "4  273.743530  291.526611  330.614044  415.199249       TP   0.848018   \n",
       "\n",
       "   cnf_score  label  \n",
       "0   0.875509      1  \n",
       "1   0.829786      1  \n",
       "2   0.819460      1  \n",
       "3   0.804641      1  \n",
       "4   0.783450      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2dd672",
   "metadata": {},
   "source": [
    "## Lets do this at Dataset level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a687bd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.COCODataset at 0x137ad5f40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d878e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 5/5000 [01:17<21:30:04, 15.50s/it]\n"
     ]
    }
   ],
   "source": [
    "gts_df, preds_df = [], []\n",
    "for d in tqdm(range(len(ds))):\n",
    "    img, annots = ds[d]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        \n",
    "    ## Ground truths\n",
    "    gt_boxes = torch.Tensor([i[\"bbox\"] for i in annots])\n",
    "    gt_boxes = xywh_to_xyxy(gt_boxes)\n",
    "    gt_labels = torch.Tensor([i[\"category_id\"] for i in annots])\n",
    "    \n",
    "    ## preds \n",
    "    pred_boxes = output[0][\"boxes\"]\n",
    "    pred_scores = output[0][\"scores\"]\n",
    "    pred_labels = output[0][\"labels\"]\n",
    "    \n",
    "    tt = SIE(0.5)\n",
    "    gt_df, pred_df = img_error.forward(gt_boxes, gt_labels, pred_boxes, pred_scores, pred_labels)\n",
    "    gts_df.append(gt_df)\n",
    "    preds_df.append(pred_df)\n",
    "    if d == 5:\n",
    "        break\n",
    "    \n",
    "gts_df = pd.concat(gts_df).reset_index(drop=True)\n",
    "preds_df = pd.concat(preds_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27e89b",
   "metadata": {},
   "source": [
    "## calculate metrics \n",
    "since we have identified TP, FP or FN for each bbox in gt and pred. now lets calculate AP for each class and then mAP of the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11a88cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 6) (153, 8)\n"
     ]
    }
   ],
   "source": [
    "tt = preds_df.sort_values(\"cnf_score\", ascending=False)\n",
    "pred_sc = tt[tt[\"label\"] == 1].reset_index(drop=True)\n",
    "gt_sc = gts_df[gts_df[\"label\"] == 1].reset_index(drop=True)\n",
    "print(gt_sc.shape, pred_sc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7312b03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>acc_tp</th>\n",
       "      <th>acc_fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344.064667</td>\n",
       "      <td>166.239029</td>\n",
       "      <td>421.646393</td>\n",
       "      <td>356.626617</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.895064</td>\n",
       "      <td>0.948951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326.498016</td>\n",
       "      <td>172.822937</td>\n",
       "      <td>396.342224</td>\n",
       "      <td>370.975037</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.967901</td>\n",
       "      <td>0.929150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508.890900</td>\n",
       "      <td>169.926651</td>\n",
       "      <td>631.921448</td>\n",
       "      <td>385.082062</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.920736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.601577</td>\n",
       "      <td>167.568085</td>\n",
       "      <td>132.564224</td>\n",
       "      <td>394.536621</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.985011</td>\n",
       "      <td>0.915256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.173676</td>\n",
       "      <td>223.436707</td>\n",
       "      <td>302.513489</td>\n",
       "      <td>316.329956</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.894396</td>\n",
       "      <td>0.875832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0  344.064667  166.239029  421.646393  356.626617       TP   0.895064   \n",
       "1  326.498016  172.822937  396.342224  370.975037       TP   0.967901   \n",
       "2  508.890900  169.926651  631.921448  385.082062       TP   0.955729   \n",
       "3    9.601577  167.568085  132.564224  394.536621       TP   0.985011   \n",
       "4  256.173676  223.436707  302.513489  316.329956       TP   0.894396   \n",
       "\n",
       "   cnf_score  label  TP  FP  acc_tp  acc_fp  \n",
       "0   0.948951      1   1   0       1       0  \n",
       "1   0.929150      1   1   0       2       0  \n",
       "2   0.920736      1   1   0       3       0  \n",
       "3   0.915256      1   1   0       4       0  \n",
       "4   0.875832      1   1   0       5       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sc[\"TP\"] = pred_sc[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"TP\" else 0)\n",
    "pred_sc[\"FP\"] = pred_sc[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"FP\" else 0)\n",
    "\n",
    "pred_sc[\"acc_tp\"] = pred_sc[\"TP\"].cumsum()\n",
    "pred_sc[\"acc_fp\"] = pred_sc[\"FP\"].cumsum()\n",
    "pred_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a46d6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>acc_tp</th>\n",
       "      <th>acc_fp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AvgFalsePosScan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344.064667</td>\n",
       "      <td>166.239029</td>\n",
       "      <td>421.646393</td>\n",
       "      <td>356.626617</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.895064</td>\n",
       "      <td>0.948951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326.498016</td>\n",
       "      <td>172.822937</td>\n",
       "      <td>396.342224</td>\n",
       "      <td>370.975037</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.967901</td>\n",
       "      <td>0.929150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508.890900</td>\n",
       "      <td>169.926651</td>\n",
       "      <td>631.921448</td>\n",
       "      <td>385.082062</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.920736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.601577</td>\n",
       "      <td>167.568085</td>\n",
       "      <td>132.564224</td>\n",
       "      <td>394.536621</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.985011</td>\n",
       "      <td>0.915256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.173676</td>\n",
       "      <td>223.436707</td>\n",
       "      <td>302.513489</td>\n",
       "      <td>316.329956</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.894396</td>\n",
       "      <td>0.875832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0  344.064667  166.239029  421.646393  356.626617       TP   0.895064   \n",
       "1  326.498016  172.822937  396.342224  370.975037       TP   0.967901   \n",
       "2  508.890900  169.926651  631.921448  385.082062       TP   0.955729   \n",
       "3    9.601577  167.568085  132.564224  394.536621       TP   0.985011   \n",
       "4  256.173676  223.436707  302.513489  316.329956       TP   0.894396   \n",
       "\n",
       "   cnf_score  label  TP  FP  acc_tp  acc_fp  precision    recall  \\\n",
       "0   0.948951      1   1   0       1       0        1.0  0.052632   \n",
       "1   0.929150      1   1   0       2       0        1.0  0.105263   \n",
       "2   0.920736      1   1   0       3       0        1.0  0.157895   \n",
       "3   0.915256      1   1   0       4       0        1.0  0.210526   \n",
       "4   0.875832      1   1   0       5       0        1.0  0.263158   \n",
       "\n",
       "   AvgFalsePosScan  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is box detection precision.\n",
    "pred_sc[\"precision\"] = pred_sc[\"acc_tp\"] / (pred_sc[\"acc_tp\"] + pred_sc[\"acc_fp\"] + 1e-16)\n",
    "pred_sc[\"recall\"] = pred_sc[\"acc_tp\"] / (gt_sc.shape[0] + 1e-16)\n",
    "pred_sc[\"AvgFalsePosScan\"] = pred_sc[\"acc_fp\"] / (gt_sc.shape[0] + 1e-16)\n",
    "pred_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7362105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\"Compute the average precision, given the recall and precision curves\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list)\n",
    "        precision: The precision curve (list)\n",
    "    # Returns\n",
    "        Average precision, precision curve, recall curve\n",
    "    \"\"\"\n",
    "\n",
    "    # Append sentinel values to beginning and end\n",
    "    mrec = np.concatenate(([0.0], recall, [recall[-1] + 0.01]))\n",
    "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
    "\n",
    "    # Compute the precision envelope\n",
    "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "\n",
    "    # Integrate area under curve\n",
    "    method = \"interp\"  # methods: 'continuous', 'interp'\n",
    "    if method == \"interp\":\n",
    "        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n",
    "        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate\n",
    "    else:  # 'continuous'\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n",
    "\n",
    "    return ap, mpre, mrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d5b1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, mpre, mrec = compute_ap(pred_sc[\"recall\"].values, pred_sc[\"precision\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be26eb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744329928970971"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfe3e0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3.5), nrows=1, ncols=1)\n",
    "ax.plot(mpre, mrec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db6971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
