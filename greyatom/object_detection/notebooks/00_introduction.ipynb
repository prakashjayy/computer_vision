{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter: Introduction to Object Detection\n",
    "- Topics\n",
    "    - Object Detection vs Classification\n",
    "    - Usecases\n",
    "    - Object Detection using computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Object Detection\n",
    "\n",
    "Object detection is the process of identifying instances of different objects inside the image. The fundamental difference between image classification and object detection is that in Image classification, we only tell whether a particular object (single class) or a list of objects (multi-class) are present or not in the image, Where as in object detection we can locate each and every instance of the object and predict both the object name (class) and its location ( rectangular coordinates (x1, y1, x2, y2)). The following diagram makes it more clear.\n",
    "\n",
    "![Image classification vs Object detection](../images/cows.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. why Object detection? \n",
    "Object detection has various use cases. It is widely used across various industries \n",
    "\n",
    "### Usecase-1 \n",
    "In China, Already about 200 million surveillance cameras are scattered around the country — to track big spenders in luxury retail stores, catch identity thieves, prevent violent crime, find fugitives, catch sleeping students in the classroom and even snag jaywalkers. In fact, nearly every one of its 1.4 billion citizens is in China’s facial recognition database. \n",
    "\n",
    "The first thing we need to do in facial recongization is to accurately localize each and every face and here is where object detection comes into picture, the below diagram shows an output of object detection model trained to accurately identify human faces given a image. (Later these faces are vectorized and matched with existing databases).\n",
    "\n",
    "Companies like [YITU](https://www.yitutech.com/en), [SenseTime](https://en.wikipedia.org/wiki/SenseTime), [Face++](https://www.faceplusplus.com/) are all multi billion dollar companies which heavily invested in these technologies. \n",
    "![Face Detection](../images/faces.png)\n",
    "source: [link](https://arxiv.org/pdf/1711.07246.pdf)\n",
    "\n",
    "\n",
    "### Usecase-2 \n",
    "Self-Driving car technology heavily uses Object detection to accurately identify other vehicles, pedistrains, traffic lights etc to understand and make sense out of the surroundings. \n",
    "\n",
    "Google's [Waymo](https://waymo.com/), [Tesla Autopilot](https://www.tesla.com/autopilot) use some object detection modules to effictively navigate on the roads without any accidents.\n",
    "\n",
    "Click on this [link](https://www.youtube.com/watch?v=VF8JuQwKQmU) To see how object detection works on roads.\n",
    "\n",
    "\n",
    "### Other Usecases\n",
    "- In Insurance, Object detection is used to localize and identify the damages to vechiles, buildings etc.\n",
    "- In Retail stores, Object detection is used to track the shoppers behaviour across the store.\n",
    "- Army, Navy and other govt institutions use to track and monitor intruders.\n",
    "- In manufacturing, Object detection is used to identify the defective locations of a product. \n",
    "\n",
    "In this way, no matter whatever industry you take, object detection is used in some form or other and is the major research topic in **Deep Learning** Community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Object Detection using computer vision\n",
    "- \n",
    "Object detection work flow is complex and yet simple if you understand what exactly is happening under the hood. Before jumping into how object detection frameworks based on Deep learning works, lets look at how object detection using computer vision was performed before deep learning era.  \n",
    "\n",
    "Object detection in its simple terms means searching for objects inside an image. Now, What's the most simple way of searching? We will be using a technique called sliding window approach. Lets take an image\n",
    "\n",
    "### 3.1 What is a sliding window?\n",
    "In the context on computer vision, a sliding window is a rectangular region of fixed width and height that slides across an image, such as in the following figure. \n",
    "\n",
    "![SlidingWindow](gifs/sliding_window.gif \"positive\")\n",
    "\n",
    "Lets look at how we can generate the above sliding windows on the image. Similar to our deep learning terminology, we have \n",
    "- kernel size: the size of the window\n",
    "- stride: number of pixels to leave before going into the next slide \n",
    "\n",
    "The following is the code to generate a window given an image, stride and kernel_size.\n",
    "```python\n",
    "def sliding_window(image, stride, kernel_size):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stride):\n",
    "        for x in range(0, image.shape[1], stride):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + kernel_size[1], x:x + kernel_size[0]])\n",
    "```\n",
    "\n",
    "To visually check how to strip each window to identify wheather there is an object or not, we can use opencv rectangle drawing function. We will use a kernel_size of (128, 128) and stride of 32 in this example.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import imageio ## For converting into gifs \n",
    "\n",
    "## Read the image\n",
    "img = cv2.imread(\"../images/cow.jpg\")\n",
    "\n",
    "## Convert to BGR format\n",
    "img = img[:, :, ::-1]\n",
    "\n",
    "## kernel_size and stride\n",
    "kernel_size = (128, 128)\n",
    "stride= 32 \n",
    "\n",
    "imgs = []\n",
    "for (x, y, window) in sliding_window(img, stride=stride, kernel_size=kernel_size):\n",
    "    # if the window does not meet our desired window size, ignore it\n",
    "    if window.shape[0] != kernel_size[0] or window.shape[1] != kernel_size[1]:\n",
    "        continue\n",
    "    # since we do not have a classifier, we'll just draw the window\n",
    "    clone = img.copy()\n",
    "    cv2.rectangle(clone, (x, y), (x + kernel_size[0], y + kernel_size[1]), (0, 255, 0), 2)\n",
    "    imgs.append(clone)\n",
    "    \n",
    "print(\"total_sliding_windows: {}\".format(len(imgs)))\n",
    "## 170 sliding windows\n",
    "    \n",
    "    \n",
    "## Convert to a gif\n",
    "import imageio\n",
    "images = []\n",
    "for img_ in imgs:\n",
    "    images.append(img_)\n",
    "imageio.mimsave('movie.gif', images)\n",
    "```\n",
    "\n",
    "In total there are 170 sliding window images. In the next section we will see how we will move from sliding window to object detection\n",
    "\n",
    "Note: [Imageio](https://imageio.github.io/) is a Python library that provides an easy interface to read and write a wide range of image data, including animated images, video, volumetric data, and scientific formats. It is cross-platform, runs on Python 2.7 and 3.4+, and is easy to install. Instrested readers can read more about the library in the link given above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - \n",
    "How many valid windows are present in an image of size (800, 800) when kernel_size is (64, 64) and stride = 64 and there is no padding ?\n",
    "\n",
    "Note: All the windows should be of shape (64, 64). We considered that there is no padding.\n",
    "\n",
    "Answer = 144\n",
    "solution:\n",
    "```python\n",
    "image = np.zeros((800, 800, 3))\n",
    "kernel_size = (64, 64)\n",
    "stride = 64\n",
    "\n",
    "windows = []\n",
    "for y in range(0, image.shape[0], stride):\n",
    "    for x in range(0, image.shape[1], stride):\n",
    "        if x+stride > image.shape[0] or y+stride > image.shape[1]:\n",
    "            continue\n",
    "        window = (x, y, image[y:y + kernel_size[1], x:x + kernel_size[0]])\n",
    "        windows.append(window)\n",
    "print(len(windows))       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 sliding windows to object detection\n",
    "Once the sliding windows are generated, it is a simple classifier problem. We will vectorize each and every sliding window using traditional computer vision techniques like [HOG descriptors](https://gurus.pyimagesearch.com/lesson-sample-histogram-of-oriented-gradients-and-car-logo-recognition/) etc, then pass on the image vector to a classifier like SVM which will tell weather a cow is present (1) or not (0) in the window.\n",
    "\n",
    "![object detection using sliding window](../images/ob_sw_process.png)\n",
    "\n",
    "The above described process is for inference. Now lets look at how we will develop something like this from scratch. Lets say we want to build an cow detector. \n",
    "- The first thing you would do is to collect a dataset which contains cows. These cows appear in different sizes, across different groups, in different locations etc. \n",
    "- Using any [image annotation tool](https://www.quora.com/What-is-the-best-image-labeling-tool-for-object-detection), we annotate the dataset for cows.\n",
    "- Now we generate sliding windows on each image to generate background images and cow images for training the classifier. This is done simply using an iou threshold (say 0.3). As shown in the below diagram, All the green boxes are background classes and all the red boxes are +ve classes.  \n",
    "![SlidingWindow2](gifs/sliding_window_with_label.gif \"label\")\n",
    "- Once the classifier is trained and accuracy metrics are satisfied, we ship the model.\n",
    "- During inference, there might be multiple sliding windows predicting the same cow. In these cases we will be using **Non-maxima supression(NMS)** techniques to remove duplicate boxes.  [Non-maxima suppression](https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/) is a simple technique to remove duplicate bounding boxes. First we will select class (cow here) and then sort all the +ve boxes using probability score. Now if two +ve bounding boxes have iou (intersection are) greater than the desired (threshold), we will remove the bounding box with lower confidence score. In this way, we will get the best bounding boxes and remove duplicates. \n",
    "\n",
    "input_image       |  output_image( After non-maxima suppression )\n",
    ":---------:|:------:\n",
    "![img1](gifs/x.png)  |  ![img_2](gifs/y.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with Sliding window approach\n",
    "Sliding window approach is a simple approach and it would not take much time to develop this code base but this simple naive approach has so many problems. First objects come in different sizes and shapes. Images in the database will be of different shape and size. Detecting an object at any scale, shape and size is challenging using sliding window approach.  We can see some images below which are available in the cocodataset (we will discuss in the next session)\n",
    "\n",
    "img1       |  img2 |  img3 |  img4 |  img5\n",
    ":---------:|:------:|:-----:|:-------:|:------:\n",
    "![img1](../images/0_coco1.jpg)  |  ![img2](../images/0_coco2.jpg) | ![img3](../images/0_coco3.jpg)  | ![img4](../images/0_coco4.jpg)| ![img5](../images/0_coco5.jpg) \n",
    "\n",
    "Computer vision researchers have found some engineering ways to deal with this. In the above case instead of using just one kernel_size and stride we can use multiple strides and kernel_size (largely derived from the dataset). Using multiple kernel_sizes and strides would generate more windows from the existing image, which will result in both training data (thus training time) and inference time also. for the research community, this gave slight improvements in accuracy. To further increase the search, they have started using **image pyramids**. \n",
    "\n",
    "\n",
    "### 3.3 What are image pyrmaids?\n",
    "An Image Pyramid is a multi-scale representation of an image. As shown below, we can see that image of width and height (x, y) are resized to (x/2, y/2), (x/4, y/4) and (x/8, y/8).  Instead of using one single image to generate windows, here we can use images of multiple scales and generate windows on each of them respectively.\n",
    "\n",
    "![image_pyramids](../images/image_pyramids.png)\n",
    "\n",
    "\n",
    "At the bottom of the pyramid we have the original image at its original size (in terms of width and height). And at each subsequent layer, the image is resized (subsampled) and optionally smoothed (usually via Gaussian blurring). More about Gaussian blurring [here](https://en.wikipedia.org/wiki/Gaussian_blur). scikit-image transforms module has pyramid_gaussian function which can generate images based on the provided downscale value. The following is the code to generate pyramids.\n",
    "\n",
    "\n",
    "```python\n",
    "from skimage.transform import pyramid_gaussian\n",
    "for (i, resized) in enumerate(pyramid_gaussian(img, downscale=1.2)):\n",
    "    # if the image is too small, break from the loop\n",
    "    if resized.shape[0] < 128 or resized.shape[1] < 128:\n",
    "        break\n",
    "    print(resized.shape)\n",
    "```\n",
    "\n",
    "![SlidingWindow3](gifs/image_pyramids.gif \"image pyramids\")\n",
    "\n",
    "\n",
    "So all together, Utilizing an image pyramid allows us to find objects in images at different scales of an image and when combined with a sliding window we can find objects in images in various locations which are of different sizes and shapes. \n",
    "\n",
    "\n",
    "## Quiz \n",
    "\n",
    "Q1) How many pyramids are present in an image of size (800, 800) using downscale of 1.5, where the smallest image cannot be less than (64, 64)?\n",
    "\n",
    "Sol) A \n",
    "\n",
    "A) 7\n",
    "B) 10\n",
    "C) 6\n",
    "D) 5\n",
    "\n",
    "\n",
    "Q2) Which of the following image sizes doesn't occur in pyramid generated on an image of size (800, 800) using downscale of 1.5, where the smallest image cannot be less than (64, 64)?\n",
    "\n",
    "sol) C \n",
    "\n",
    "A) (356, 356, 3)\n",
    "B) (238, 238, 3)\n",
    "C) (64, 64, 3)\n",
    "D) (106, 106, 3)\n",
    "\n",
    "\n",
    "Code for the Q1 and Q2.\n",
    "```python\n",
    "for (i, resized) in enumerate(pyramid_gaussian(img, downscale=1.5)):\n",
    "    ## Only images of greater than minimum size can be used\n",
    "    if resized.shape[0] >= 64 or resized.shape[1] >= 64:\n",
    "        print(i, resized.shape)\n",
    "```\n",
    "\n",
    "## Task \n",
    "How many windows are present on an image of size (800, 800), kernel_size = 64, stride = 64 and no padding while using  downscale=2 and min_image_size = 128?\n",
    "\n",
    "Instructions:\n",
    "- minimum size of the image in the pyrmaid can be of (128, 128). So we need to discard all other remaining pyramids.\n",
    "- There is no padding. So x+stride <= image.shape[0] and y+stride <= image.shape[1]\n",
    "\n",
    "Ans) 455 \n",
    "\n",
    "Solution:\n",
    "\n",
    "```python\n",
    "from skimage.transform import pyramid_gaussian\n",
    "img = np.zeros((800, 800, 3))\n",
    "\n",
    "windows = []\n",
    "for (i, resized) in enumerate(pyramid_gaussian(img, downscale=1.2)):\n",
    "    ## Only images of greater than minimum size can be used\n",
    "    if resized.shape[0] >= 128 or resized.shape[1] >= 128:\n",
    "        print(resized.shape)\n",
    "        ## Window Along the y axis\n",
    "        for y in range(0, resized.shape[0], stride):\n",
    "            ## Window along the x axis\n",
    "            for x in range(0, resized.shape[1], stride):\n",
    "                if x+stride > resized.shape[0] or y+stride > resized.shape[1]:\n",
    "                    continue\n",
    "                # capture the window\n",
    "                window = (x, y, resized[y:y + kernel_size[1], x:x + kernel_size[0]])\n",
    "                ## Append the window to the list\n",
    "                windows.append(window)\n",
    "print(len(windows)) \n",
    "```\n",
    "\n",
    "\n",
    "## Final notes.\n",
    "In this first section we have seen \n",
    "- the difference between object detection and Image classification.\n",
    "- We have seen various applications where object detection is used. \n",
    "- We have seen how object detection works using traditional computer vision techniques. We have defined sliding windows, kernel_size, strides, image_pyrmaids and NMS (non-maxima supression) etc. This terminology is very important as this is extensively used in the coming sections. \n",
    "\n",
    "In the next section we will have a look at the datasets available for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras)",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
