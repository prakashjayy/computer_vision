{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e61445f",
   "metadata": {},
   "source": [
    "## Object detection metrics and errors \n",
    "Object detection and instance segmentation primarily use one metric to judge performance: `mean Average Precision (mAP )`. How do we interpret it? For a metric like `accuracy` we know that 90% means that the model is wrong `10%` of the time. we will see the following things in this blog.\n",
    "- what does a mAP of `63.2%` actually mean? \n",
    "- why do we use `mAP` as a metric in object detection? \n",
    "- what kind of errors are associated with your model which is hampering your overall score?\n",
    "    - A `false positive` can be a \n",
    "        - duplicate detection\n",
    "        - misclassification\n",
    "        - mislocalization\n",
    "        - confusion with background\n",
    "        - both a misclassification and mislocalization.\n",
    "    - a false negative could be a \n",
    "        - completely missed ground truth, \n",
    "        - potentially correct prediction could have just been misclassified or mislocalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97995983",
   "metadata": {},
   "source": [
    "There are 3 places our detector can affect mAP \n",
    "- outputting false positives during the matching step, \n",
    "- not outputting true positives (i.e., false negatives) for computing recall, \n",
    "- having incorrect calibration (i.e., outputting a higher confidence for a false positive then a true positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684ae92",
   "metadata": {},
   "source": [
    "The difficulty of the code has increased because\n",
    "- we have multiple classes \n",
    "- we have multiple thresholds \n",
    "- we have to do for both mask and bbox\n",
    "- we have multiple metrics [small, medium, large, mAR, mAP]\n",
    "\n",
    "\n",
    "we will simplify the code by \n",
    "- using one single threshold (mAP 50)\n",
    "- only bbox \n",
    "- only mAP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f889a8",
   "metadata": {},
   "source": [
    "First lets calculate `mAP` of the model. we will First use `torchvision` retinanet on COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ffee100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.ops.boxes import _box_xywh_to_xyxy as xywh_to_xyxy\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08831cc4",
   "metadata": {},
   "source": [
    "> Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d5becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.detection.retinanet.RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn_v2(weights = weights, num_classes=91)\n",
    "model.eval()\n",
    "preprocess= weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed320099",
   "metadata": {},
   "source": [
    "> Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e999a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset:\n",
    "    def __init__(self, img_root, annot_loc, transforms=None):\n",
    "        self.coco = COCO(annot_loc)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.img_ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta = self.coco.imgs[img_id]\n",
    "        img_loc = self.img_root / img_meta[\"file_name\"]\n",
    "        img = Image.open(img_loc)\n",
    "        \n",
    "        ## Load annotations \n",
    "        annot_ids = self.coco.getAnnIds(imgIds=[img_id])\n",
    "        annots = self.coco.loadAnns(ids = annot_ids)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            return self.transforms(img).unsqueeze(0), annots\n",
    "        return img, annots\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.coco.imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb26427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.59s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annot_loc = \"data/coco/annotations/instances_val2017.json\"\n",
    "img_root = \"data/coco/val2017/\"\n",
    "ds = COCODataset(img_root, annot_loc=annot_loc, transforms=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad532c16",
   "metadata": {},
   "source": [
    "> Load a single image with its annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c093cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, annots = ds[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b1ea35",
   "metadata": {},
   "source": [
    "> Generate predictions\n",
    "\n",
    "- This model uses an nms threshold of 0.5. check `model.nms_thresh`\n",
    "- The output is a dict with boxes, scores, labels as keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82496f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "output[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c942558",
   "metadata": {},
   "source": [
    "## check FP's, FN's and TP's for each bbox.\n",
    "Each bbox (both gt and pred), we need to assign TP, FP or FN label. We will do this at 3 levels\n",
    "- single image single class `SISCE` \n",
    "- single image all classes `SIE`\n",
    "- Dataset level `DE`\n",
    "where `E` stands for Error. \n",
    "\n",
    "### SISCE: single image, single class error\n",
    "- this works on single image and for a single class.\n",
    "- It calculates IOU between gt and pred of the same class bboxes. \n",
    "- For gt, it assigns TP or FN label\n",
    "- For preds, it assigns TP or FP label.\n",
    "- creats gt and preds df with scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387f82f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182, 4]) torch.Size([182]) torch.Size([182])\n"
     ]
    }
   ],
   "source": [
    "pred_boxes = output[0][\"boxes\"]\n",
    "pred_scores = output[0][\"scores\"]\n",
    "pred_labels = output[0][\"labels\"]\n",
    "print(pred_boxes.shape, pred_scores.shape, pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b0c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26]) torch.Size([26, 4])\n"
     ]
    }
   ],
   "source": [
    "gt_boxes = torch.Tensor([i[\"bbox\"] for i in annots])\n",
    "gt_boxes = xywh_to_xyxy(gt_boxes)\n",
    "gt_labels = torch.Tensor([i[\"category_id\"] for i in annots])\n",
    "print(gt_labels.shape, gt_boxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e06d4",
   "metadata": {},
   "source": [
    "for each predicted bounding box we need to see if it has a correct match or not. we will do this for each class in each image first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ea032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([57, 4]) torch.Size([57]) torch.Size([13, 4])\n"
     ]
    }
   ],
   "source": [
    "categories = list(ds.coco.cats.keys())\n",
    "req_cat = categories[0]\n",
    "req_gt_boxes = gt_boxes[gt_labels ==1]\n",
    "req_pred_boxes = pred_boxes[pred_labels == 1]\n",
    "req_pred_scores = pred_scores[pred_labels==1]\n",
    "print(req_cat, req_pred_boxes.shape, req_pred_scores.shape, req_gt_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "01e5b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SISCE:\n",
    "    #SingleImage_SingleClassError\n",
    "    #\n",
    "    def __init__(self, iou_thr):\n",
    "        self.iou_thr = iou_thr\n",
    "    \n",
    "    def find_all_matches(self, c1: Union[torch.Tensor, np.asarray], c2:Union[torch.Tensor, np.asarray]):\n",
    "        all_matches = np.empty((0, 3))\n",
    "        if (len(c1) == 0) or (len(c2) == 0):\n",
    "            return all_matches\n",
    "        iou = torchvision.ops.box_iou(c1, c2).numpy()\n",
    "        want_idx = np.where(iou > self.iou_thr)\n",
    "        all_matches = []\n",
    "        for i in range(want_idx[0].shape[0]):\n",
    "            all_matches.append(\n",
    "                [\n",
    "                    want_idx[0][i],\n",
    "                    want_idx[1][i],\n",
    "                    iou[want_idx[0][i], want_idx[1][i]],\n",
    "                ]\n",
    "            )\n",
    "        ## [N, 3]: i, j, score. [gt_index, pred_index, iou_score]\n",
    "        all_matches = np.array(all_matches)\n",
    "        if all_matches.shape[0] > 0:  # if there is match\n",
    "            all_matches = all_matches[all_matches[:, 2].argsort()[::-1]]\n",
    "            all_matches = all_matches[np.unique(all_matches[:, 1], return_index=True)[1]]\n",
    "            all_matches = all_matches[all_matches[:, 2].argsort()[::-1]]\n",
    "            all_matches = all_matches[np.unique(all_matches[:, 0], return_index=True)[1]]\n",
    "        return all_matches \n",
    "    \n",
    "    def find_gt_metrics(self, c1: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        # wheather a gt bbox is TP(matcheed with a predication) or FN(was not recognized by the alogrithm)\n",
    "        c1_tt = []\n",
    "        for num, gt_ctscanannot in enumerate(c1):\n",
    "            TP_FP_FN = \"FN\"\n",
    "            if len(all_matches) > 0:\n",
    "                if num in all_matches[:, 0].tolist():\n",
    "                    TP_FP_FN = \"TP\"\n",
    "            c1_tt.append(TP_FP_FN)\n",
    "        assert len(c1) == len(c1_tt), \"there is a mismatch between number of nodules and labels\"\n",
    "        return c1_tt\n",
    "    \n",
    "    def get_gt_pd(self, c1: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        c1_tt = self.find_gt_metrics(c1, all_matches)\n",
    "        return self.to_df(c1, c1_tt)\n",
    "    \n",
    "    def to_df(self, c1, c1_tt):\n",
    "        if isinstance(c1, torch.Tensor):\n",
    "            c1 = c1.numpy()\n",
    "        df = pd.DataFrame(c1)\n",
    "        df.columns = [\"x1\", \"y1\", \"x2\", \"y2\"]\n",
    "        df[\"TP_FP_FN\"] = c1_tt\n",
    "        return df \n",
    "    \n",
    "    \n",
    "    def get_pred_pd(self, c1: Union[torch.Tensor, np.asarray], scores: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        c2_tt = self.find_pred_metrics(c1, all_matches)\n",
    "        df = self.to_df(c1, [i[0] for i in c2_tt])\n",
    "        df[\"iou_score\"] = [i[1] for i in c2_tt]\n",
    "        if isinstance(scores, torch.Tensor):\n",
    "            scores = scores.numpy()\n",
    "        df[\"cnf_score\"] = scores\n",
    "        return df \n",
    "        \n",
    "    \n",
    "    def find_pred_metrics(self, c1: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        c2_tt = []\n",
    "        for num, pred_ctscaannot in enumerate(c1):\n",
    "            iou_score, TP_FP_FN = 0.0, \"FP\"\n",
    "            iou_score = 0.0\n",
    "            if len(all_matches) > 0:\n",
    "                if num in np.int64(all_matches[:, 1]):\n",
    "                    index = int(np.where(np.int64(all_matches[:, 1]) == num)[0])\n",
    "                    iou_score = all_matches[index][2]\n",
    "                    TP_FP_FN = \"TP\"\n",
    "            c2_tt.append([TP_FP_FN, iou_score])\n",
    "        assert len(c1) == len(c2_tt), \"there is a mismatch between number of nodules and labels\"\n",
    "        return c2_tt\n",
    "    \n",
    "    def forward(self, gt, pred, scores):\n",
    "        matches = self.find_all_matches(gt, pred)\n",
    "        preds_df = self.get_pred_pd(pred, scores, matches)\n",
    "        gt_df = self.get_gt_pd(gt, matches)\n",
    "        return gt_df, preds_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ad685d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = SISCE(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02ee57b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.76189595],\n",
       "       [ 1.        ,  4.        ,  0.84801769],\n",
       "       [ 2.        ,  0.        ,  0.92562395],\n",
       "       [ 3.        ,  2.        ,  0.88024729],\n",
       "       [ 4.        ,  8.        ,  0.63157892],\n",
       "       [ 5.        ,  6.        ,  0.88249034],\n",
       "       [ 6.        , 10.        ,  0.8462857 ],\n",
       "       [ 7.        , 11.        ,  0.87101638],\n",
       "       [ 8.        , 13.        ,  0.77039939],\n",
       "       [ 9.        , 17.        ,  0.84931129],\n",
       "       [10.        ,  7.        ,  0.89238977],\n",
       "       [11.        ,  3.        ,  0.85208613],\n",
       "       [12.        ,  5.        ,  0.65539688]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches = error.find_all_matches(req_gt_boxes, req_pred_boxes)\n",
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "363bf102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210682</td>\n",
       "      <td>265.643738</td>\n",
       "      <td>110.534225</td>\n",
       "      <td>422.256592</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.925624</td>\n",
       "      <td>0.875509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313.360962</td>\n",
       "      <td>284.719269</td>\n",
       "      <td>392.871094</td>\n",
       "      <td>421.843689</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.829786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429.111725</td>\n",
       "      <td>274.314087</td>\n",
       "      <td>533.618408</td>\n",
       "      <td>404.633026</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.880247</td>\n",
       "      <td>0.819460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494.161133</td>\n",
       "      <td>276.724335</td>\n",
       "      <td>586.270264</td>\n",
       "      <td>385.799164</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.852086</td>\n",
       "      <td>0.804641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.743530</td>\n",
       "      <td>291.526611</td>\n",
       "      <td>330.614044</td>\n",
       "      <td>415.199249</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.848018</td>\n",
       "      <td>0.783450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0    0.210682  265.643738  110.534225  422.256592       TP   0.925624   \n",
       "1  313.360962  284.719269  392.871094  421.843689       TP   0.761896   \n",
       "2  429.111725  274.314087  533.618408  404.633026       TP   0.880247   \n",
       "3  494.161133  276.724335  586.270264  385.799164       TP   0.852086   \n",
       "4  273.743530  291.526611  330.614044  415.199249       TP   0.848018   \n",
       "\n",
       "   cnf_score  \n",
       "0   0.875509  \n",
       "1   0.829786  \n",
       "2   0.819460  \n",
       "3   0.804641  \n",
       "4   0.783450  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_sisc  = error.get_pred_pd(req_pred_boxes, req_pred_scores, all_matches)\n",
    "print(pred_df_sisc.shape)\n",
    "pred_df_sisc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7653ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322.570007</td>\n",
       "      <td>290.809998</td>\n",
       "      <td>387.660004</td>\n",
       "      <td>418.429993</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.640015</td>\n",
       "      <td>292.109985</td>\n",
       "      <td>324.590027</td>\n",
       "      <td>421.759979</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.920000</td>\n",
       "      <td>266.880005</td>\n",
       "      <td>116.369995</td>\n",
       "      <td>422.669983</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424.119995</td>\n",
       "      <td>270.589996</td>\n",
       "      <td>531.589966</td>\n",
       "      <td>400.130005</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.269989</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>285.289978</td>\n",
       "      <td>316.100006</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN\n",
       "0  322.570007  290.809998  387.660004  418.429993       TP\n",
       "1  273.640015  292.109985  324.590027  421.759979       TP\n",
       "2    1.920000  266.880005  116.369995  422.669983       TP\n",
       "3  424.119995  270.589996  531.589966  400.130005       TP\n",
       "4  259.269989  281.000000  285.289978  316.100006       TP"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df_sisc = error.get_gt_pd(req_gt_boxes, all_matches)\n",
    "print(gt_df_sisc.shape)\n",
    "gt_df_sisc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfcc3b",
   "metadata": {},
   "source": [
    "### SIE: single image error \n",
    "- this basically evaluates at image level across all the classes.\n",
    "- in case if you want to limit to single class we can use the earlier function or set the class label here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7dc40337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIE:\n",
    "    # Single image error\n",
    "    def __init__(self, iou_thr):\n",
    "        self.sisce = SISCE(iou_thr=iou_thr)\n",
    "    \n",
    "    def forward_class(self, \n",
    "                      gts: torch.Tensor, \n",
    "                      gt_labels: torch.Tensor, \n",
    "                      preds: torch.Tensor, \n",
    "                      pred_scores: torch.Tensor, \n",
    "                      pred_labels: torch.Tensor, \n",
    "                      req_label: int):\n",
    "        req_gt_boxes = gts[gt_labels ==req_label]\n",
    "        req_pred_boxes = preds[pred_labels == req_label]\n",
    "        req_pred_scores = pred_scores[pred_labels == req_label]\n",
    "        gt_df, pred_df = self.sisce.forward(req_gt_boxes, req_pred_boxes, req_pred_scores)\n",
    "        gt_df[\"label\"] = gt_labels[gt_labels == req_label].numpy()\n",
    "        pred_df[\"label\"] = pred_labels[pred_labels==req_label]\n",
    "        return gt_df, pred_df \n",
    "    \n",
    "    def forward(self, \n",
    "                gt: torch.Tensor, \n",
    "                gt_labels: torch.Tensor, \n",
    "                pred: torch.Tensor, \n",
    "                pred_score: torch.Tensor, \n",
    "                pred_labels: torch.Tensor,):\n",
    "        gts_df, preds_df = [], []\n",
    "        labels = torch.hstack([pred_labels, gt_labels]).unique()\n",
    "        for label in labels.unique():\n",
    "            gt_df, pred_df = self.forward_class(gt, gt_labels, pred, pred_score, pred_labels, req_label= label)\n",
    "            gts_df.append(gt_df)\n",
    "            preds_df.append(pred_df)            \n",
    "        return pd.concat(gts_df).reset_index(drop=True), pd.concat(preds_df).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b52892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_error = SIE(iou_thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "76b5bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 6) (182, 8)\n"
     ]
    }
   ],
   "source": [
    "gts_df, preds_df = img_error.forward(gt_boxes, gt_labels, pred_boxes, pred_scores, pred_labels)\n",
    "print(gts_df.shape, preds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7f83aed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322.570007</td>\n",
       "      <td>290.809998</td>\n",
       "      <td>387.660004</td>\n",
       "      <td>418.429993</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.640015</td>\n",
       "      <td>292.109985</td>\n",
       "      <td>324.590027</td>\n",
       "      <td>421.759979</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.920000</td>\n",
       "      <td>266.880005</td>\n",
       "      <td>116.369995</td>\n",
       "      <td>422.669983</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424.119995</td>\n",
       "      <td>270.589996</td>\n",
       "      <td>531.589966</td>\n",
       "      <td>400.130005</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.269989</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>285.289978</td>\n",
       "      <td>316.100006</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  label\n",
       "0  322.570007  290.809998  387.660004  418.429993       TP    1.0\n",
       "1  273.640015  292.109985  324.590027  421.759979       TP    1.0\n",
       "2    1.920000  266.880005  116.369995  422.669983       TP    1.0\n",
       "3  424.119995  270.589996  531.589966  400.130005       TP    1.0\n",
       "4  259.269989  281.000000  285.289978  316.100006       TP    1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ea2618fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210682</td>\n",
       "      <td>265.643738</td>\n",
       "      <td>110.534225</td>\n",
       "      <td>422.256592</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.925624</td>\n",
       "      <td>0.875509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313.360962</td>\n",
       "      <td>284.719269</td>\n",
       "      <td>392.871094</td>\n",
       "      <td>421.843689</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.829786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429.111725</td>\n",
       "      <td>274.314087</td>\n",
       "      <td>533.618408</td>\n",
       "      <td>404.633026</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.880247</td>\n",
       "      <td>0.819460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494.161133</td>\n",
       "      <td>276.724335</td>\n",
       "      <td>586.270264</td>\n",
       "      <td>385.799164</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.852086</td>\n",
       "      <td>0.804641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.743530</td>\n",
       "      <td>291.526611</td>\n",
       "      <td>330.614044</td>\n",
       "      <td>415.199249</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.848018</td>\n",
       "      <td>0.783450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0    0.210682  265.643738  110.534225  422.256592       TP   0.925624   \n",
       "1  313.360962  284.719269  392.871094  421.843689       TP   0.761896   \n",
       "2  429.111725  274.314087  533.618408  404.633026       TP   0.880247   \n",
       "3  494.161133  276.724335  586.270264  385.799164       TP   0.852086   \n",
       "4  273.743530  291.526611  330.614044  415.199249       TP   0.848018   \n",
       "\n",
       "   cnf_score  label  \n",
       "0   0.875509      1  \n",
       "1   0.829786      1  \n",
       "2   0.819460      1  \n",
       "3   0.804641      1  \n",
       "4   0.783450      1  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55077a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
