{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e61445f",
   "metadata": {},
   "source": [
    "## Object detection metrics and errors \n",
    "Object detection and instance segmentation primarily use one metric to judge performance: `mean Average Precision (mAP )`. How do we interpret it? For a metric like `accuracy` we know that 90% means that the model is wrong `10%` of the time. we will see the following things in this blog.\n",
    "- what does a mAP of `63.2%` actually mean? \n",
    "- why do we use `mAP` as a metric in object detection? \n",
    "- what kind of errors are associated with your model which is hampering your overall score?\n",
    "    - A `false positive` can be a \n",
    "        - duplicate detection\n",
    "        - misclassification\n",
    "        - mislocalization\n",
    "        - confusion with background\n",
    "        - both a misclassification and mislocalization.\n",
    "    - a false negative could be a \n",
    "        - completely missed ground truth, \n",
    "        - potentially correct prediction could have just been misclassified or mislocalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97995983",
   "metadata": {},
   "source": [
    "There are 3 places our detector can affect mAP \n",
    "- outputting false positives during the matching step, \n",
    "- not outputting true positives (i.e., false negatives) for computing recall, \n",
    "- having incorrect calibration (i.e., outputting a higher confidence for a false positive then a true positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684ae92",
   "metadata": {},
   "source": [
    "The difficulty of the code has increased because\n",
    "- we have multiple classes \n",
    "- we have multiple thresholds \n",
    "- we have to do for both mask and bbox\n",
    "- we have multiple metrics [small, medium, large, mAR, mAP]\n",
    "\n",
    "\n",
    "we will simplify the code by \n",
    "- using one single threshold (mAP 50)\n",
    "- only bbox \n",
    "- only mAP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f889a8",
   "metadata": {},
   "source": [
    "First lets calculate `mAP` of the model. we will First use `torchvision` retinanet on COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ffee100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.ops.boxes import _box_xywh_to_xyxy as xywh_to_xyxy\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08831cc4",
   "metadata": {},
   "source": [
    "> Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d5becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.detection.retinanet.RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn_v2(weights = weights, num_classes=91)\n",
    "model.eval()\n",
    "preprocess= weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed320099",
   "metadata": {},
   "source": [
    "> Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e999a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset:\n",
    "    def __init__(self, img_root, annot_loc, transforms=None):\n",
    "        self.coco = COCO(annot_loc)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.img_ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta = self.coco.imgs[img_id]\n",
    "        img_loc = self.img_root / img_meta[\"file_name\"]\n",
    "        img = Image.open(img_loc)\n",
    "        \n",
    "        ## Load annotations \n",
    "        annot_ids = self.coco.getAnnIds(imgIds=[img_id])\n",
    "        annots = self.coco.loadAnns(ids = annot_ids)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            return self.transforms(img).unsqueeze(0), annots\n",
    "        return img, annots\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.coco.imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb26427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annot_loc = \"data/coco/annotations/instances_val2017.json\"\n",
    "img_root = \"data/coco/val2017/\"\n",
    "ds = COCODataset(img_root, annot_loc=annot_loc, transforms=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86783c2",
   "metadata": {},
   "source": [
    "> Load a single image with its annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c093cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, annots = ds[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7566ad1",
   "metadata": {},
   "source": [
    "> Generate predictions\n",
    "\n",
    "- This model uses an nms threshold of 0.5. check `model.nms_thresh`\n",
    "- The output is a dict with boxes, scores, labels as keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82496f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes', 'scores', 'labels'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "output[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c942558",
   "metadata": {},
   "source": [
    "## check FP's, FN's and TP's for each bbox.\n",
    "Each bbox (both gt and pred), we need to assign TP, FP or FN label. We will do this at 3 levels\n",
    "- single image single class `SISCE` \n",
    "- single image all classes `SIE`\n",
    "- Dataset level `DE`\n",
    "where `E` stands for Error. \n",
    "\n",
    "### SISCE: single image, single class error\n",
    "- this works on single image and for a single class.\n",
    "- It calculates IOU between gt and pred of the same class bboxes. \n",
    "- For gt, it assigns TP or FN label\n",
    "- For preds, it assigns TP or FP label.\n",
    "- creats gt and preds df with scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387f82f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182, 4]) torch.Size([182]) torch.Size([182])\n"
     ]
    }
   ],
   "source": [
    "pred_boxes = output[0][\"boxes\"]\n",
    "pred_scores = output[0][\"scores\"]\n",
    "pred_labels = output[0][\"labels\"]\n",
    "print(pred_boxes.shape, pred_scores.shape, pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b0c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26]) torch.Size([26, 4])\n"
     ]
    }
   ],
   "source": [
    "gt_boxes = torch.Tensor([i[\"bbox\"] for i in annots])\n",
    "gt_boxes = xywh_to_xyxy(gt_boxes)\n",
    "gt_labels = torch.Tensor([i[\"category_id\"] for i in annots])\n",
    "print(gt_labels.shape, gt_boxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e06d4",
   "metadata": {},
   "source": [
    "for each predicted bounding box we need to see if it has a correct match or not. we will do this for each class in each image first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ea032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([57, 4]) torch.Size([57]) torch.Size([13, 4])\n"
     ]
    }
   ],
   "source": [
    "categories = list(ds.coco.cats.keys())\n",
    "req_cat = categories[0]\n",
    "req_gt_boxes = gt_boxes[gt_labels ==1]\n",
    "req_pred_boxes = pred_boxes[pred_labels == 1]\n",
    "req_pred_scores = pred_scores[pred_labels==1]\n",
    "print(req_cat, req_pred_boxes.shape, req_pred_scores.shape, req_gt_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e5b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SISCE:\n",
    "    #SingleImage_SingleClassError\n",
    "    #\n",
    "    def __init__(self, iou_thr):\n",
    "        self.iou_thr = iou_thr\n",
    "    \n",
    "    def find_all_matches(self, c1: Union[torch.Tensor, np.asarray], c2:Union[torch.Tensor, np.asarray]):\n",
    "        all_matches = np.empty((0, 3))\n",
    "        if (len(c1) == 0) or (len(c2) == 0):\n",
    "            return all_matches\n",
    "        iou = torchvision.ops.box_iou(c1, c2).numpy()\n",
    "        want_idx = np.where(iou > self.iou_thr)\n",
    "        all_matches = []\n",
    "        for i in range(want_idx[0].shape[0]):\n",
    "            all_matches.append(\n",
    "                [\n",
    "                    want_idx[0][i],\n",
    "                    want_idx[1][i],\n",
    "                    iou[want_idx[0][i], want_idx[1][i]],\n",
    "                ]\n",
    "            )\n",
    "        ## [N, 3]: i, j, score. [gt_index, pred_index, iou_score]\n",
    "        all_matches = np.array(all_matches)\n",
    "        if all_matches.shape[0] > 0:  # if there is match\n",
    "            all_matches = all_matches[all_matches[:, 2].argsort()[::-1]]\n",
    "            all_matches = all_matches[np.unique(all_matches[:, 1], return_index=True)[1]]\n",
    "            all_matches = all_matches[all_matches[:, 2].argsort()[::-1]]\n",
    "            all_matches = all_matches[np.unique(all_matches[:, 0], return_index=True)[1]]\n",
    "        return all_matches \n",
    "    \n",
    "    def find_gt_metrics(self, c1: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        # wheather a gt bbox is TP(matcheed with a predication) or FN(was not recognized by the alogrithm)\n",
    "        c1_tt = []\n",
    "        for num, gt_ctscanannot in enumerate(c1):\n",
    "            TP_FP_FN = \"FN\"\n",
    "            if len(all_matches) > 0:\n",
    "                if num in all_matches[:, 0].tolist():\n",
    "                    TP_FP_FN = \"TP\"\n",
    "            c1_tt.append(TP_FP_FN)\n",
    "        assert len(c1) == len(c1_tt), \"there is a mismatch between number of nodules and labels\"\n",
    "        return c1_tt\n",
    "    \n",
    "    def get_gt_pd(self, c1: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        c1_tt = self.find_gt_metrics(c1, all_matches)\n",
    "        return self.to_df(c1, c1_tt)\n",
    "    \n",
    "    def to_df(self, c1, c1_tt):\n",
    "        if isinstance(c1, torch.Tensor):\n",
    "            c1 = c1.numpy()\n",
    "        df = pd.DataFrame(c1)\n",
    "        df.columns = [\"x1\", \"y1\", \"x2\", \"y2\"]\n",
    "        df[\"TP_FP_FN\"] = c1_tt\n",
    "        return df \n",
    "    \n",
    "    \n",
    "    def get_pred_pd(self, c1: Union[torch.Tensor, np.asarray], scores: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        c2_tt = self.find_pred_metrics(c1, all_matches)\n",
    "        df = self.to_df(c1, [i[0] for i in c2_tt])\n",
    "        df[\"iou_score\"] = [i[1] for i in c2_tt]\n",
    "        if isinstance(scores, torch.Tensor):\n",
    "            scores = scores.numpy()\n",
    "        df[\"cnf_score\"] = scores\n",
    "        return df \n",
    "        \n",
    "    \n",
    "    def find_pred_metrics(self, c1: Union[torch.Tensor, np.asarray], all_matches: np.asarray):\n",
    "        c2_tt = []\n",
    "        for num, pred_ctscaannot in enumerate(c1):\n",
    "            iou_score, TP_FP_FN = 0.0, \"FP\"\n",
    "            iou_score = 0.0\n",
    "            if len(all_matches) > 0:\n",
    "                if num in np.int64(all_matches[:, 1]):\n",
    "                    index = int(np.where(np.int64(all_matches[:, 1]) == num)[0])\n",
    "                    iou_score = all_matches[index][2]\n",
    "                    TP_FP_FN = \"TP\"\n",
    "            c2_tt.append([TP_FP_FN, iou_score])\n",
    "        assert len(c1) == len(c2_tt), \"there is a mismatch between number of nodules and labels\"\n",
    "        return c2_tt\n",
    "    \n",
    "    def forward(self, gt, pred, scores):\n",
    "        matches = self.find_all_matches(gt, pred)\n",
    "        preds_df = self.get_pred_pd(pred, scores, matches)\n",
    "        gt_df = self.get_gt_pd(gt, matches)\n",
    "        return gt_df, preds_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad685d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = SISCE(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ee57b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.76189595],\n",
       "       [ 1.        ,  4.        ,  0.84801769],\n",
       "       [ 2.        ,  0.        ,  0.92562395],\n",
       "       [ 3.        ,  2.        ,  0.88024729],\n",
       "       [ 4.        ,  8.        ,  0.63157892],\n",
       "       [ 5.        ,  6.        ,  0.88249034],\n",
       "       [ 6.        , 10.        ,  0.8462857 ],\n",
       "       [ 7.        , 11.        ,  0.87101638],\n",
       "       [ 8.        , 13.        ,  0.77039939],\n",
       "       [ 9.        , 17.        ,  0.84931129],\n",
       "       [10.        ,  7.        ,  0.89238977],\n",
       "       [11.        ,  3.        ,  0.85208613],\n",
       "       [12.        ,  5.        ,  0.65539688]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches = error.find_all_matches(req_gt_boxes, req_pred_boxes)\n",
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2f43f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210682</td>\n",
       "      <td>265.643738</td>\n",
       "      <td>110.534225</td>\n",
       "      <td>422.256592</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.925624</td>\n",
       "      <td>0.875509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313.360962</td>\n",
       "      <td>284.719269</td>\n",
       "      <td>392.871094</td>\n",
       "      <td>421.843689</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.829786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429.111725</td>\n",
       "      <td>274.314087</td>\n",
       "      <td>533.618408</td>\n",
       "      <td>404.633026</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.880247</td>\n",
       "      <td>0.819460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494.161133</td>\n",
       "      <td>276.724335</td>\n",
       "      <td>586.270264</td>\n",
       "      <td>385.799164</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.852086</td>\n",
       "      <td>0.804641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.743530</td>\n",
       "      <td>291.526611</td>\n",
       "      <td>330.614044</td>\n",
       "      <td>415.199249</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.848018</td>\n",
       "      <td>0.783450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0    0.210682  265.643738  110.534225  422.256592       TP   0.925624   \n",
       "1  313.360962  284.719269  392.871094  421.843689       TP   0.761896   \n",
       "2  429.111725  274.314087  533.618408  404.633026       TP   0.880247   \n",
       "3  494.161133  276.724335  586.270264  385.799164       TP   0.852086   \n",
       "4  273.743530  291.526611  330.614044  415.199249       TP   0.848018   \n",
       "\n",
       "   cnf_score  \n",
       "0   0.875509  \n",
       "1   0.829786  \n",
       "2   0.819460  \n",
       "3   0.804641  \n",
       "4   0.783450  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_sisc  = error.get_pred_pd(req_pred_boxes, req_pred_scores, all_matches)\n",
    "print(pred_df_sisc.shape)\n",
    "pred_df_sisc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7653ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322.570007</td>\n",
       "      <td>290.809998</td>\n",
       "      <td>387.660004</td>\n",
       "      <td>418.429993</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.640015</td>\n",
       "      <td>292.109985</td>\n",
       "      <td>324.590027</td>\n",
       "      <td>421.759979</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.920000</td>\n",
       "      <td>266.880005</td>\n",
       "      <td>116.369995</td>\n",
       "      <td>422.669983</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424.119995</td>\n",
       "      <td>270.589996</td>\n",
       "      <td>531.589966</td>\n",
       "      <td>400.130005</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.269989</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>285.289978</td>\n",
       "      <td>316.100006</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN\n",
       "0  322.570007  290.809998  387.660004  418.429993       TP\n",
       "1  273.640015  292.109985  324.590027  421.759979       TP\n",
       "2    1.920000  266.880005  116.369995  422.669983       TP\n",
       "3  424.119995  270.589996  531.589966  400.130005       TP\n",
       "4  259.269989  281.000000  285.289978  316.100006       TP"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df_sisc = error.get_gt_pd(req_gt_boxes, all_matches)\n",
    "print(gt_df_sisc.shape)\n",
    "gt_df_sisc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bd4b7",
   "metadata": {},
   "source": [
    "### SIE: single image error \n",
    "- this basically evaluates at image level across all the classes.\n",
    "- in case if you want to limit to single class we can use the earlier function or set the class label here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc067db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIE:\n",
    "    # Single image error\n",
    "    def __init__(self, iou_thr):\n",
    "        self.sisce = SISCE(iou_thr=iou_thr)\n",
    "    \n",
    "    def forward_class(self, \n",
    "                      gts: torch.Tensor, \n",
    "                      gt_labels: torch.Tensor, \n",
    "                      preds: torch.Tensor, \n",
    "                      pred_scores: torch.Tensor, \n",
    "                      pred_labels: torch.Tensor, \n",
    "                      req_label: int):\n",
    "        req_gt_boxes = gts[gt_labels ==req_label]\n",
    "        req_pred_boxes = preds[pred_labels == req_label]\n",
    "        req_pred_scores = pred_scores[pred_labels == req_label]\n",
    "        gt_df, pred_df = self.sisce.forward(req_gt_boxes, req_pred_boxes, req_pred_scores)\n",
    "        gt_df[\"label\"] = gt_labels[gt_labels == req_label].numpy()\n",
    "        pred_df[\"label\"] = pred_labels[pred_labels==req_label]\n",
    "        return gt_df, pred_df \n",
    "    \n",
    "    def forward(self, \n",
    "                gt: torch.Tensor, \n",
    "                gt_labels: torch.Tensor, \n",
    "                pred: torch.Tensor, \n",
    "                pred_score: torch.Tensor, \n",
    "                pred_labels: torch.Tensor,):\n",
    "        gts_df, preds_df = [], []\n",
    "        labels = torch.hstack([pred_labels, gt_labels]).unique()\n",
    "        for label in labels.unique():\n",
    "            gt_df, pred_df = self.forward_class(gt, gt_labels, pred, pred_score, pred_labels, req_label= label)\n",
    "            gts_df.append(gt_df)\n",
    "            preds_df.append(pred_df)            \n",
    "        return pd.concat(gts_df).reset_index(drop=True), pd.concat(preds_df).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04eceffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_error = SIE(iou_thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d9e7c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 6) (182, 8)\n"
     ]
    }
   ],
   "source": [
    "gts_df, preds_df = img_error.forward(gt_boxes, gt_labels, pred_boxes, pred_scores, pred_labels)\n",
    "print(gts_df.shape, preds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb52226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322.570007</td>\n",
       "      <td>290.809998</td>\n",
       "      <td>387.660004</td>\n",
       "      <td>418.429993</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.640015</td>\n",
       "      <td>292.109985</td>\n",
       "      <td>324.590027</td>\n",
       "      <td>421.759979</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.920000</td>\n",
       "      <td>266.880005</td>\n",
       "      <td>116.369995</td>\n",
       "      <td>422.669983</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424.119995</td>\n",
       "      <td>270.589996</td>\n",
       "      <td>531.589966</td>\n",
       "      <td>400.130005</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.269989</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>285.289978</td>\n",
       "      <td>316.100006</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  label\n",
       "0  322.570007  290.809998  387.660004  418.429993       TP    1.0\n",
       "1  273.640015  292.109985  324.590027  421.759979       TP    1.0\n",
       "2    1.920000  266.880005  116.369995  422.669983       TP    1.0\n",
       "3  424.119995  270.589996  531.589966  400.130005       TP    1.0\n",
       "4  259.269989  281.000000  285.289978  316.100006       TP    1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e965fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210682</td>\n",
       "      <td>265.643738</td>\n",
       "      <td>110.534225</td>\n",
       "      <td>422.256592</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.925624</td>\n",
       "      <td>0.875509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313.360962</td>\n",
       "      <td>284.719269</td>\n",
       "      <td>392.871094</td>\n",
       "      <td>421.843689</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.829786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429.111725</td>\n",
       "      <td>274.314087</td>\n",
       "      <td>533.618408</td>\n",
       "      <td>404.633026</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.880247</td>\n",
       "      <td>0.819460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494.161133</td>\n",
       "      <td>276.724335</td>\n",
       "      <td>586.270264</td>\n",
       "      <td>385.799164</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.852086</td>\n",
       "      <td>0.804641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.743530</td>\n",
       "      <td>291.526611</td>\n",
       "      <td>330.614044</td>\n",
       "      <td>415.199249</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.848018</td>\n",
       "      <td>0.783450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0    0.210682  265.643738  110.534225  422.256592       TP   0.925624   \n",
       "1  313.360962  284.719269  392.871094  421.843689       TP   0.761896   \n",
       "2  429.111725  274.314087  533.618408  404.633026       TP   0.880247   \n",
       "3  494.161133  276.724335  586.270264  385.799164       TP   0.852086   \n",
       "4  273.743530  291.526611  330.614044  415.199249       TP   0.848018   \n",
       "\n",
       "   cnf_score  label  \n",
       "0   0.875509      1  \n",
       "1   0.829786      1  \n",
       "2   0.819460      1  \n",
       "3   0.804641      1  \n",
       "4   0.783450      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2dd672",
   "metadata": {},
   "source": [
    "## Lets do this at Dataset level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a687bd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.COCODataset at 0x13674bf10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d878e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 5/5000 [01:22<22:55:37, 16.52s/it]\n"
     ]
    }
   ],
   "source": [
    "gts_df, preds_df = [], []\n",
    "for d in tqdm(range(len(ds))):\n",
    "    img, annots = ds[d]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        \n",
    "    ## Ground truths\n",
    "    gt_boxes = torch.Tensor([i[\"bbox\"] for i in annots])\n",
    "    gt_boxes = xywh_to_xyxy(gt_boxes)\n",
    "    gt_labels = torch.Tensor([i[\"category_id\"] for i in annots])\n",
    "    \n",
    "    ## preds \n",
    "    pred_boxes = output[0][\"boxes\"]\n",
    "    pred_scores = output[0][\"scores\"]\n",
    "    pred_labels = output[0][\"labels\"]\n",
    "    \n",
    "    tt = SIE(0.5)\n",
    "    gt_df, pred_df = img_error.forward(gt_boxes, gt_labels, pred_boxes, pred_scores, pred_labels)\n",
    "    gts_df.append(gt_df)\n",
    "    preds_df.append(pred_df)\n",
    "    \n",
    "gts_df = pd.concat(gts_df).reset_index(drop=True)\n",
    "preds_df = pd.concat(preds_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff793c",
   "metadata": {},
   "source": [
    "## calculate metrics \n",
    "since we have identified TP, FP or FN for each bbox in gt and pred. now lets calculate AP for each class and then mAP of the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "479868e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 6) (153, 8)\n"
     ]
    }
   ],
   "source": [
    "tt = preds_df.sort_values(\"cnf_score\", ascending=False)\n",
    "pred_sc = tt[tt[\"label\"] == 1].reset_index(drop=True)\n",
    "gt_sc = gts_df[gts_df[\"label\"] == 1].reset_index(drop=True)\n",
    "print(gt_sc.shape, pred_sc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd080916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>acc_tp</th>\n",
       "      <th>acc_fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344.064667</td>\n",
       "      <td>166.239029</td>\n",
       "      <td>421.646393</td>\n",
       "      <td>356.626617</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.895064</td>\n",
       "      <td>0.948951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326.498016</td>\n",
       "      <td>172.822937</td>\n",
       "      <td>396.342224</td>\n",
       "      <td>370.975037</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.967901</td>\n",
       "      <td>0.929150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508.890900</td>\n",
       "      <td>169.926651</td>\n",
       "      <td>631.921448</td>\n",
       "      <td>385.082062</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.920736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.601577</td>\n",
       "      <td>167.568085</td>\n",
       "      <td>132.564224</td>\n",
       "      <td>394.536621</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.985011</td>\n",
       "      <td>0.915256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.173676</td>\n",
       "      <td>223.436707</td>\n",
       "      <td>302.513489</td>\n",
       "      <td>316.329956</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.894396</td>\n",
       "      <td>0.875832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0  344.064667  166.239029  421.646393  356.626617       TP   0.895064   \n",
       "1  326.498016  172.822937  396.342224  370.975037       TP   0.967901   \n",
       "2  508.890900  169.926651  631.921448  385.082062       TP   0.955729   \n",
       "3    9.601577  167.568085  132.564224  394.536621       TP   0.985011   \n",
       "4  256.173676  223.436707  302.513489  316.329956       TP   0.894396   \n",
       "\n",
       "   cnf_score  label  TP  FP  acc_tp  acc_fp  \n",
       "0   0.948951      1   1   0       1       0  \n",
       "1   0.929150      1   1   0       2       0  \n",
       "2   0.920736      1   1   0       3       0  \n",
       "3   0.915256      1   1   0       4       0  \n",
       "4   0.875832      1   1   0       5       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sc[\"TP\"] = pred_sc[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"TP\" else 0)\n",
    "pred_sc[\"FP\"] = pred_sc[\"TP_FP_FN\"].apply(lambda x: 1 if x == \"FP\" else 0)\n",
    "\n",
    "pred_sc[\"acc_tp\"] = pred_sc[\"TP\"].cumsum()\n",
    "pred_sc[\"acc_fp\"] = pred_sc[\"FP\"].cumsum()\n",
    "pred_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "073799cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>TP_FP_FN</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>cnf_score</th>\n",
       "      <th>label</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>acc_tp</th>\n",
       "      <th>acc_fp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AvgFalsePosScan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344.064667</td>\n",
       "      <td>166.239029</td>\n",
       "      <td>421.646393</td>\n",
       "      <td>356.626617</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.895064</td>\n",
       "      <td>0.948951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326.498016</td>\n",
       "      <td>172.822937</td>\n",
       "      <td>396.342224</td>\n",
       "      <td>370.975037</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.967901</td>\n",
       "      <td>0.929150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508.890900</td>\n",
       "      <td>169.926651</td>\n",
       "      <td>631.921448</td>\n",
       "      <td>385.082062</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.920736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.601577</td>\n",
       "      <td>167.568085</td>\n",
       "      <td>132.564224</td>\n",
       "      <td>394.536621</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.985011</td>\n",
       "      <td>0.915256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.173676</td>\n",
       "      <td>223.436707</td>\n",
       "      <td>302.513489</td>\n",
       "      <td>316.329956</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.894396</td>\n",
       "      <td>0.875832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2 TP_FP_FN  iou_score  \\\n",
       "0  344.064667  166.239029  421.646393  356.626617       TP   0.895064   \n",
       "1  326.498016  172.822937  396.342224  370.975037       TP   0.967901   \n",
       "2  508.890900  169.926651  631.921448  385.082062       TP   0.955729   \n",
       "3    9.601577  167.568085  132.564224  394.536621       TP   0.985011   \n",
       "4  256.173676  223.436707  302.513489  316.329956       TP   0.894396   \n",
       "\n",
       "   cnf_score  label  TP  FP  acc_tp  acc_fp  precision    recall  \\\n",
       "0   0.948951      1   1   0       1       0        1.0  0.052632   \n",
       "1   0.929150      1   1   0       2       0        1.0  0.105263   \n",
       "2   0.920736      1   1   0       3       0        1.0  0.157895   \n",
       "3   0.915256      1   1   0       4       0        1.0  0.210526   \n",
       "4   0.875832      1   1   0       5       0        1.0  0.263158   \n",
       "\n",
       "   AvgFalsePosScan  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is box detection precision.\n",
    "pred_sc[\"precision\"] = pred_sc[\"acc_tp\"] / (pred_sc[\"acc_tp\"] + pred_sc[\"acc_fp\"] + 1e-16)\n",
    "pred_sc[\"recall\"] = pred_sc[\"acc_tp\"] / (gt_sc.shape[0] + 1e-16)\n",
    "pred_sc[\"AvgFalsePosScan\"] = pred_sc[\"acc_fp\"] / (gt_sc.shape[0] + 1e-16)\n",
    "pred_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d5c3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\"Compute the average precision, given the recall and precision curves\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list)\n",
    "        precision: The precision curve (list)\n",
    "    # Returns\n",
    "        Average precision, precision curve, recall curve\n",
    "    \"\"\"\n",
    "\n",
    "    # Append sentinel values to beginning and end\n",
    "    mrec = np.concatenate(([0.0], recall, [recall[-1] + 0.01]))\n",
    "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
    "\n",
    "    # Compute the precision envelope\n",
    "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "\n",
    "    # Integrate area under curve\n",
    "    method = \"interp\"  # methods: 'continuous', 'interp'\n",
    "    if method == \"interp\":\n",
    "        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n",
    "        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate\n",
    "    else:  # 'continuous'\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n",
    "\n",
    "    return ap, mpre, mrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3802b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, mpre, mrec = compute_ap(pred_sc[\"recall\"].values, pred_sc[\"precision\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51163b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744329928970971"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47f8ec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3.5), nrows=1, ncols=1)\n",
    "ax.plot(mpre, mrec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27521b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
